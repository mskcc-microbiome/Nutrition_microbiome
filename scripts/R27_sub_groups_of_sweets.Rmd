---
title: "sub groups of the sweets"
output: html_document
date: "2025-06-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(broom.mixed)
library(brms)   
library(ggpubr)
library(tidybayes)
library(cowplot)
library(ggridges)
library(brmstools)
library(bayesplot)
options(mc.cores = parallel::detectCores())
rstan::rstan_options(auto_write = TRUE)
theme_set(theme_tidybayes() + panel_border())
ncores <- parallel::detectCores()
```

- Major Critiques and Challenges

Lack of Interpretability (The "Black Box" Problem): This is the biggest critique. The model's output can be incredibly difficult to understand. What does the coefficient for "apples" mean after being adjusted for 499 other foods, many of which are highly correlated? The complexity often obscures, rather than clarifies, the biological story.

Extreme Collinearity: Dietary data is notoriously collinear (e.g., people who eat hot dogs often eat hot dog buns). Putting hundreds of correlated food items into one model can make the individual coefficient estimates highly unstable and unreliable. The model may struggle to assign the effect correctly between two highly correlated foods.

Risk of Overfitting: Without very careful and robust regularization, a model with so many predictors is at high risk of "overfitting"â€”finding spurious patterns in the random noise of your specific dataset that will not be reproducible in the future.

It May Be Overkill: If the dominant biological signal comes from a broad nutritional pattern (like high sugar intake), modeling every single food item individually might not provide any more insight than the more logical, hierarchical approach you are taking.

# the sub groups of sweets

```{r}
# what's the subgroup of sweets?    
sweets3 <- read_tsv('../data/NodeLabelsMCT.txt', col_types = 'cc')  %>%  
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 3) 


sweets2 <- read_tsv('../data/NodeLabelsMCT.txt', col_types = 'cc')  %>% 
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 2)      

sweets4 <- read_tsv('../data/NodeLabelsMCT.txt', col_types = 'cc')  %>% 
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 4)      
```

```{r}
dtb  <- read_csv('../data/152_combined_DTB.csv')

# testing the solid and liquid sugar foods association with abx !     
dtb_ <- dtb %>% 
  select(pid, fdrt, Food_NSC, Food_code, dehydrated_weight, Sugars_g) 
```
```{r}
daily_intake_summary <- dtb_ %>%

  # Create a new 'food_category' column based on FNDDS codes.
  # The case_when() function checks conditions in order.
  # This is why we put the more specific 3-digit rules before the general 1-digit rules.
  mutate(
    food_category = case_when(
      
      # Rule for high-sugar sports drinks, grouping them with other liquid sweets
      Food_code == "95320200" ~ "fg_Liquid_Sweets",
      # Rule for low-sugar/electrolyte drinks, creating a new category
      Food_code %in% c("95322200", "95330100") ~ "fg_Functional_Beverages",
      
      # --- Define Oral Nutritional Supplements (ONS) ---
      str_starts(Food_code, "951") | str_starts(Food_code, "952") ~ "fg_ONS",
      
      # Solid Sweets & Sugars
      str_starts(Food_code, "911") | str_starts(Food_code, "913") |
      str_starts(Food_code, "914") | str_starts(Food_code, "915") |
      str_starts(Food_code, "917") | str_starts(Food_code, "918") ~ "fg_Solid_Sweets",

      # Liquid Sugar (Sugar-Sweetened Beverages)
      str_starts(Food_code, "924") | str_starts(Food_code, "925") |
      str_starts(Food_code, "926") ~ "fg_Liquid_Sweets",
      
       # Define Coffee & Tea
      str_starts(Food_code, "921") | str_starts(Food_code, "922") |
      str_starts(Food_code, "923") ~ "fg_Coffee_Tea",

      # --- Define the 8 main food categories using the first digit ---
      str_starts(Food_code, "1") ~ "fg_milk",
      str_starts(Food_code, "2") ~ "fg_meat",
      str_starts(Food_code, "3") ~ "fg_egg",
      str_starts(Food_code, "4") ~ "fg_legume",
      str_starts(Food_code, "5") ~ "fg_grain",
      str_starts(Food_code, "6") ~ "fg_fruit",
      str_starts(Food_code, "7") ~ "fg_veggie",
      str_starts(Food_code, "8") ~ "fg_oils",

      # Any food code that doesn't match the rules above will be assigned NA
      TRUE ~ NA_character_
    )
  ) %>%

  # Remove any rows that were not assigned to a category (e.g., ONS, water, etc.)
  filter(!is.na(food_category)) %>%

  # Group the data by patient, day, and our new food category
  group_by(pid, fdrt, food_category) %>%

  # Calculate the total dehydrated weight for each group
  # The na.rm = TRUE argument handles any missing weight values gracefully
  summarise(
    total_dehydrated_weight = sum(dehydrated_weight, na.rm = TRUE),
    total_sugars = sum(Sugars_g, na.rm = TRUE),
    .groups = 'drop' # Ungroup the data after summarizing
  )

# --- View the final summary table ---
# This table is now in a "tidy" format, ready for analysis or plotting.
# Each row shows the total grams of a food category consumed by a patient on a specific day.

# You can also use pivot_wider() to create a "wide" table where each food category
# has its own column. This format is often required for statistical models.
daily_intake_wide <- daily_intake_summary %>%
  pivot_wider(
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fill = 0 # Fill in 0 for categories a patient didn't eat on a given day
  )


# finding the prior two day average of the above groups
stool_samples_df <- read_csv('../data/153_combined_META.csv') %>% 
  select(pid, sdrt, sampleid, simpson_reciprocal, empirical, intensity, EN, TPN)
```


```{r}
# ---  Calculate the 2-Day Prior Average Intake ---

# This single pipe performs the entire calculation.
# It joins the two tables, filters for the correct time window,
# calculates the average, and reshapes the data into the final format.

stool_samples_with_window <- stool_samples_df %>%
  mutate(
    # The 2-day window starts 2 days before the stool sample...
    window_start = sdrt - 2,
    # ...and ends 1 day before the stool sample.
    window_end = sdrt - 1
  )

# Now, perform the join using these new, pre-calculated columns
final_model_data <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    # The join is performed using direct column comparisons
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # This step reshapes the data into the final wide format needed for modeling.
  # It calculates the average over the 2-day window.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_intake_" # Adds a clear prefix to the new columns
  ) %>%
    # This divides all the new intake columns by 100.
  # The across() function efficiently applies the same operation to many columns.
  mutate(across(starts_with("avg_intake_"), ~ .x / 100)) %>%
  
  # Joins back the original stool sample info
  right_join(stool_samples_df, by = c("pid", "sdrt")) %>% 
  mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left')) %>% 
  mutate(intensity = factor(intensity, levels = c('nonablative','reduced','ablative'))) %>% 
  mutate(pid = factor(pid)) 

# repeat the above process but only calculate the prior two day of sugar in those food categories
final_model_sugar <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    # The join is performed using direct column comparisons
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # This step reshapes the data into the final wide format needed for modeling.
  # It calculates the average over the 2-day window.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_sugars,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_sugar_intake_" # Adds a clear prefix to the new columns
  ) %>%
    # This divides all the new intake columns by 100.
  # The across() function efficiently applies the same operation to many columns.
  mutate(across(starts_with("avg_sugar_intake_"), ~ .x / 100)) %>%
  
  # Joins back the original stool sample info
  right_join(stool_samples_df, by = c("pid", "sdrt")) %>% 
  mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left')) %>% 
  mutate(intensity = factor(intensity, levels = c('nonablative','reduced','ablative'))) %>% 
  mutate(pid = factor(pid)) 


```

# iterative modeling 

```{r}

# --- Step 2: Define the food categories for the iterative analysis ---

# Define the "sweets" subcategories that will be swapped in and out of the model
sweets_subcategories_to_test <- c(
  "avg_intake_fg_Solid_Sweets",
  "avg_intake_fg_Liquid_Sweets",
  "avg_intake_fg_ONS",
  "avg_intake_fg_Coffee_Tea",
  "avg_intake_fg_Functional_Beverages"
)

# Define the 8 main food groups that will be included as covariates in every model
main_food_groups <- c(
  "avg_intake_fg_milk", "avg_intake_fg_meat", "avg_intake_fg_egg", "avg_intake_fg_legume", "avg_intake_fg_grain",
  "avg_intake_fg_fruit", "avg_intake_fg_veggie", "avg_intake_fg_oils"
)


# --- Step 3: Create a function that runs one iteration of the Bayesian model ---
# This function takes one of the "sweets" subcategory names as input,
# builds the full model formula, sets all priors, runs the model,
# and returns the key results.
run_iterative_model <- function(sweet_variable, data) {

  # Combine the main food groups and the current sweet variable
  all_food_vars <- c(main_food_groups, sweet_variable)

  # Create the interaction terms for all food variables in this iteration
  interaction_terms <- paste(all_food_vars, "empirical", sep = ":")

  # Build the full formula string dynamically
  formula_string <- paste(
    "log(simpson_reciprocal) ~ 0 + intensity + empirical + TPN + EN +",
    paste(interaction_terms, collapse = " + "),
    "+ (1 | pid) + (1 | timebin)"
  )

  # Convert the string to a formula object
  formula <- brms::bf(as.formula(formula_string))

  # Build the priors by adding them together.
  # This single prior() call applies to all coefficients listed in `all_food_coefs`.
  priors <-
    prior(normal(0, 1), class = 'b') + # General prior for all food effects
    # Specific priors that override the general one for non-food covariates
    prior(normal(0, 0.1), class = 'b', coef = "TPNTRUE") +
    prior(normal(0, 0.1), class = 'b', coef = "ENTRUE") +
    prior(normal(0, 0.5), class = 'b', coef = "empiricalTRUE") +
    prior(normal(2, .1), class = 'b', coef = "intensityablative") +
    prior(normal(2, .1), class = 'b', coef = "intensityreduced") +
    prior(normal(2, .1), class = 'b', coef = "intensitynonablative")

  # Fit the model (using fewer iterations for this example to run quickly)
  model_fit <- brm(
    formula = formula,
    data = data,
    prior = priors,
    warmup = 1000, iter = 3000,
    chains = 2, cores = 10, # Adjust cores as needed
    seed = 123,
    silent = 2
  )

  # Tidy the output and return only the interaction term for the sweet subcategory
  tidy(model_fit, conf.int = TRUE) %>%
    filter(term == paste0("empiricalTRUE:", sweet_variable))
}


# --- Step 4: Run the iterative analysis using purrr::map ---
# This will apply the function to each "sweets" subcategory.
# This step will take a significant amount of time to run.
all_results <- map(
  sweets_subcategories_to_test,
  ~run_iterative_model(sweet_variable = .x, data = final_model_data)
)
```

```{r}
# Combine the list of results into a single, clean data frame
comparison_df <- bind_rows(all_results) %>%
  # Clean up the term name to be used as a label
  mutate(food_category = str_remove(term, "empiricalTRUE:"))

# Create a forest plot to visualize and compare the effects
ggplot(comparison_df, aes(x = estimate, y = fct_reorder(food_category, estimate))) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(size = 4, color = "dodgerblue") +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2, linewidth = 1, color = "dodgerblue") +
  labs(
    title = "Interaction Effect of Sweet Subcategories with Antibiotics on Diversity",
    subtitle = "Each estimate is from a separate model controlling for other main food groups",
    x = "Interaction Coefficient (Effect per 100g intake during antibiotic exposure)",
    y = "Sweet Subcategory"
  ) +
  theme_bw(base_size = 14)
```

# coffee and tea sugar proportion 

```{r}
merged_sugar <- final_model_data %>% 
  full_join(final_model_sugar %>% select(pid : avg_sugar_intake_fg_Functional_Beverages))

```

```{r}
plot_data <- merged_sugar %>%
  # Select only the columns we need for this plot
  select(pid,sdrt,  starts_with("avg_intake_"), starts_with("avg_sugar_intake_")) %>%
  # Pivot the data from a wide format to a long format
  pivot_longer(
    cols = avg_intake_fg_Coffee_Tea:avg_sugar_intake_fg_Functional_Beverages,
    names_to = "metric",
    values_to = "grams"
  ) %>%
  # Extract the food category name from the column name
  mutate(
    food_category = str_remove(metric, "avg_intake_|avg_sugar_intake_"),
    metric_type = if_else(str_starts(metric, "avg_sugar_intake_"), "sugar", "total")
  ) %>%
  # Reshape again to have total intake and sugar intake in separate columns
  select(pid,sdrt, food_category, metric_type, grams) %>%
  # revert it back to original value by * 100
  mutate(grams = grams * 100) %>% 
  pivot_wider(
    names_from = metric_type,
    values_from = grams
  ) %>%
  # Calculate the overall average intake across all samples for each category
  group_by(food_category) %>%
  summarise(
    avg_total_intake = mean(total, na.rm = TRUE),
    avg_sugar_intake = mean(sugar, na.rm = TRUE)
  ) %>%
  # Calculate the proportion of sugar for sorting purposes
  mutate(
    sugar_proportion = avg_sugar_intake / avg_total_intake
  ) %>%
  # Calculate the non-sugar portion for the stacked bar
  mutate(
    avg_nonsugar_intake = avg_total_intake - avg_sugar_intake
  ) %>%
  # Reshape one last time for easy plotting with ggplot
  pivot_longer(
    cols = c(avg_sugar_intake, avg_nonsugar_intake),
    names_to = "intake_type",
    values_to = "grams"
  ) %>%
  # Clean up names for the plot legend
  mutate(
    intake_type = if_else(intake_type == "avg_sugar_intake", "Sugar", "Non-Sugar Mass"),
    # Clean up food category names for the axis labels
    food_category = str_remove(food_category, "fg_") %>% str_replace_all("_", " "),
    # Reorder the 'food_category' factor based on the sugar proportion
    # The '.desc = TRUE' ensures it's in descending order (highest % at the top)
    food_category = fct_reorder(food_category, sugar_proportion, .desc = F)
  )


# --- Step 3: Create the Sorted Stacked Bar Chart ---

ggplot(plot_data, aes(x = grams, y = food_category, fill = intake_type)) +
  # Use geom_col which is an alias for geom_bar(stat="identity")
  geom_col() +
  # Use a color palette that clearly distinguishes sugar
  scale_fill_manual(values = c("Sugar" = "#FF6B6B", "Non-Sugar Mass" = "#BDBDBD")) +
  # Add informative labels
  labs(
    title = "Average Sugar Content by Food Category",
    subtitle = "Categories are sorted by the percentage of sugar content",
    x = "Average Dehydrated Weight Consumed (grams)",
    y = "Food Category",
    fill = "Component"
  ) +
  # Use a clean theme
  theme_bw() +
  theme(legend.position = "bottom")

```

```{r}
# find the top foods in the coffee/tea sub group
#  Filter, Summarize, and Prepare Data for Plotting ---

# This data wrangling pipe will isolate the coffee/tea items, find the top
# contributors, and calculate their sugar content for visualization.
coffee_tea_plot_data <- dtb_ %>%
  # Ensure Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%

  # Filter for only the food codes corresponding to Coffee & Tea
  filter(str_starts(Food_code, "921") | str_starts(Food_code, "922") | str_starts(Food_code, "923")) %>%

  # Group by the specific food name to aggregate all consumption records
  group_by(Food_NSC) %>%

  # Calculate the total intake and total sugar for each specific food item
  summarise(
    total_intake = sum(dehydrated_weight, na.rm = TRUE),
    total_sugar = sum(Sugars_g, na.rm = TRUE)
  ) %>%
  
  # Keep only the top 10 most consumed items for a clean plot
  slice_max(order_by = total_intake, n = 10) %>%

  # Calculate the non-sugar portion for the stacked bar
  mutate(
    non_sugar_mass = total_intake - total_sugar
  ) %>%

  # Reshape the data into a "long" format for easy plotting with ggplot
  pivot_longer(
    cols = c(total_sugar, non_sugar_mass),
    names_to = "component",
    values_to = "grams"
  ) %>%
  # Clean up names for the plot legend
  mutate(
    component = if_else(component == "total_sugar", "Sugar", "Non-Sugar Mass")
  )
```


```{r}
# --- Step 3: Create the Stacked Bar Chart ---

ggplot(coffee_tea_plot_data, aes(x = grams, y = fct_reorder(Food_NSC, grams, .fun = sum), fill = component)) +
  # Use geom_col to create the bars
  geom_col() +
  # Use a color palette that clearly distinguishes sugar
  scale_fill_manual(values = c("Sugar" = "#FF6B6B", "Non-Sugar Mass" = "#BDBDBD")) +
  # Add informative labels
  labs(
    title = "Top 10 Consumed Items in the Coffee & Tea Category",
    subtitle = "Showing total intake and the proportion from sugar",
    x = "Total Dehydrated Weight Consumed (grams)",
    y = "Food Item",
    fill = "Component"
  ) +
  # Use a clean theme
  theme_bw() +
  theme(legend.position = "bottom")
```


# the first 2 digit sub-group  

```{r}
# This pipe creates a tidy summary of daily intake per category.
daily_intake_summary <- dtb %>%
  # Ensures Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%
  # Create a new 'food_category' column based on the FNDDS code prefix.
  # This logic now uses the first two digits for the 9x categories.
  mutate(
    food_category = case_when(
      # --- Rules for the "Sugars, Sweets, and Beverages" major group ---
      str_starts(Food_code, "91") ~ "Sugars_and_sweets",
      str_starts(Food_code, "92") ~ "Nonalcoholic_beverages",
      str_starts(Food_code, "93") ~ "Alcoholic_beverages",
      str_starts(Food_code, "94") ~ "Water",
      str_starts(Food_code, "95") ~ "Formulated_beverages",

      # --- Rules for the other main food groups (using the first digit) ---
      str_starts(Food_code, "1") ~ "fg_milk",
      str_starts(Food_code, "2") ~ "fg_meat",
      str_starts(Food_code, "3") ~ "fg_egg",
      str_starts(Food_code, "4") ~ "fg_legume",
      str_starts(Food_code, "5") ~ "fg_grain",
      str_starts(Food_code, "6") ~ "fg_fruit",
      str_starts(Food_code, "7") ~ "fg_veggie",
      str_starts(Food_code, "8") ~ "fg_oils",
      TRUE ~ NA_character_
    )
  ) %>%
  # Removes any rows that were not assigned to a category
  filter(!is.na(food_category)) %>%
  # Groups the data to sum up weights for each category within a patient-day
  group_by(pid, fdrt, food_category) %>%
  # Calculates the total dehydrated weight for each group
  summarise(
    total_dehydrated_weight = sum(dehydrated_weight, na.rm = TRUE),
    .groups = 'drop'
  )


# --- Part 2: Calculate 2-Day Prior Average Intake for Each Stool Sample ---

# Create helper columns for the time window.
stool_samples_with_window <- stool_samples_df %>%
  mutate(
    window_start = sdrt - 2,
    window_end = sdrt - 1
  )

# Perform the join and calculate the averages.
final_model_data <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # Reshape the data into the final wide format needed for modeling.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_intake_" # Adds a clear prefix to the new columns
  ) %>%
  # This divides all the new intake columns by 100 for easier model interpretation.
  mutate(across(starts_with("avg_intake_"), ~ .x / 100)) %>%
  # Joins back the original stool sample info.
  right_join(stool_samples_df, by = c("pid", "sdrt")) %>% 
  mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left')) %>% 
  mutate(intensity = factor(intensity, levels = c('nonablative','reduced','ablative'))) %>% 
  mutate(pid = factor(pid)) 


# View the final, model-ready table.
# The columns are now based on the 2-digit FNDDS subgroups.
print(final_model_data)

```
```{r}
# --- Step 2: Define the food categories for the iterative analysis ---

# Define the "sweets" subcategories that will be swapped in and out of the model
sweets_subcategories_to_test <- c(
  "avg_intake_Nonalcoholic_beverages",
  "avg_intake_Sugars_and_sweets",
  "avg_intake_Water",
  "avg_intake_Formulated_beverages"
)

# Define the 8 main food groups that will be included as covariates in every model
main_food_groups <- c(
  "avg_intake_fg_milk", "avg_intake_fg_meat", "avg_intake_fg_egg", "avg_intake_fg_legume", "avg_intake_fg_grain",
  "avg_intake_fg_fruit", "avg_intake_fg_veggie", "avg_intake_fg_oils"
)


# --- Step 3: Create a function that runs one iteration of the Bayesian model ---
# This function takes one of the "sweets" subcategory names as input,
# builds the full model formula, sets all priors, runs the model,
# and returns the key results.
run_iterative_model <- function(sweet_variable, data) {

  # Combine the main food groups and the current sweet variable
  all_food_vars <- c(main_food_groups, sweet_variable)

  # Create the interaction terms for all food variables in this iteration
  interaction_terms <- paste(all_food_vars, "empirical", sep = ":")

  # Build the full formula string dynamically
  formula_string <- paste(
    "log(simpson_reciprocal) ~ 0 + intensity + empirical + TPN + EN +",
    paste(interaction_terms, collapse = " + "),
    "+ (1 | pid) + (1 | timebin)"
  )

  # Convert the string to a formula object
  formula <- brms::bf(as.formula(formula_string))

  # Build the priors by adding them together.
  # This single prior() call applies to all coefficients listed in `all_food_coefs`.
  priors <-
    prior(normal(0, 1), class = 'b') + # General prior for all food effects
    # Specific priors that override the general one for non-food covariates
    prior(normal(0, 0.1), class = 'b', coef = "TPNTRUE") +
    prior(normal(0, 0.1), class = 'b', coef = "ENTRUE") +
    prior(normal(0, 0.5), class = 'b', coef = "empiricalTRUE") +
    prior(normal(2, .1), class = 'b', coef = "intensityablative") +
    prior(normal(2, .1), class = 'b', coef = "intensityreduced") +
    prior(normal(2, .1), class = 'b', coef = "intensitynonablative")

  # Fit the model (using fewer iterations for this example to run quickly)
  model_fit <- brm(
    formula = formula,
    data = data,
    prior = priors,
    warmup = 1000, iter = 3000,
    chains = 2, cores = 10, # Adjust cores as needed
    seed = 123,
    silent = 2
  )

  # Tidy the output and return only the interaction term for the sweet subcategory
  tidy(model_fit, conf.int = TRUE)  # it is the 95% CI by default
}


# --- Step 4: Run the iterative analysis using purrr::map ---
# This will apply the function to each "sweets" subcategory.
# This step will take a significant amount of time to run.
all_results <- map(
  sweets_subcategories_to_test,
  ~run_iterative_model(sweet_variable = .x, data = final_model_data)
)

names(all_results) <- sweets_subcategories_to_test
```

```{r}
# Combine the list of results into a single, clean data frame
comparison_df <- bind_rows(all_results) %>%
  # Clean up the term name to be used as a label
  mutate(food_category = str_remove(term, "empiricalTRUE:")) %>%
  mutate(food_category = str_remove(food_category, "avg_intake_"))
```



```{r}
# ---  Calculate Summary Statistics for Plotting ---

# Calculate N (number of consumption events) and sugar proportion for each category
summary_stats <- dtb %>%
  # Ensures Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%
  # Create a new 'food_category' column based on the FNDDS code prefix.
  # This logic now uses the first two digits for the 9x categories.
  mutate(
    food_category = case_when(
      # --- Rules for the "Sugars, Sweets, and Beverages" major group ---
      str_starts(Food_code, "91") ~ "Sugars_and_sweets",
      str_starts(Food_code, "92") ~ "Nonalcoholic_beverages",
      str_starts(Food_code, "93") ~ "Alcoholic_beverages",
      str_starts(Food_code, "94") ~ "Water",
      str_starts(Food_code, "95") ~ "Formulated_beverages",

      # --- Rules for the other main food groups (using the first digit) ---
      str_starts(Food_code, "1") ~ "fg_milk",
      str_starts(Food_code, "2") ~ "fg_meat",
      str_starts(Food_code, "3") ~ "fg_egg",
      str_starts(Food_code, "4") ~ "fg_legume",
      str_starts(Food_code, "5") ~ "fg_grain",
      str_starts(Food_code, "6") ~ "fg_fruit",
      str_starts(Food_code, "7") ~ "fg_veggie",
      str_starts(Food_code, "8") ~ "fg_oils",
      TRUE ~ NA_character_
    )
  ) %>%
  # Removes any rows that were not assigned to a category
  filter(!is.na(food_category)) %>%
  # We only need the food category and the weights for this summary
  select(food_category, dehydrated_weight, Sugars_g) %>%
  # Group by the food category to summarize
  group_by(food_category) %>%
  summarise(
    # Count the number of times this category was consumed (N)
    n_events = n(),
    # Calculate the total weight and total sugar consumed for the category
    total_intake = sum(dehydrated_weight, na.rm = TRUE),
    total_sugar = sum(Sugars_g, na.rm = TRUE)
  ) %>%
  # Calculate the overall sugar proportion
  mutate(
    sugar_proportion = total_sugar / total_intake
  ) %>%
  # Join these stats back to the model results
  right_join(comparison_df, by = "food_category") %>%
  # Clean up the name for plotting
  mutate(
    label = str_remove(food_category, "avg_intake_fg_") %>% str_replace_all("_", " ")
  )

```


```{r}
# Plot A: Forest plot of model results, annotated with N as a proxy for power
forest_plot <- ggplot(summary_stats, aes(x = estimate, y = fct_reorder(label, estimate))) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(size = 4, color = "#118AB2") +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2, linewidth = 1, color = "#118AB2") +
  labs(
    title = "A) Model Effect Size & Precision",
    subtitle = "Interaction effect on diversity during antibiotic use",
    x = "Interaction Coefficient",
    y = "Food Subcategory"
  ) +
  theme_bw(base_size = 12)

forest_plot
```

## Full bayesian results


```{r}
# --- Step 2: Create a Function to Generate the Plots ---
# This function encapsulates all the cleaning and plotting logic.
# It takes a dataframe of model results and a title string as input.
create_effects_plot <- function(results_df, plot_title) {

  # This pipe filters for the fixed effects and creates clean, human-readable labels.
  cleaned_effects <- results_df %>%
    # Keep only the fixed effects
    filter(effect == "fixed") %>%
    # Create a new column to distinguish main effects from interactions
    mutate(
      effect_type = if_else(str_detect(term, ":"), "Interaction", "Main Effect"),
      # Create clean labels for plotting
      clean_term = term %>%
        str_remove_all("empiricalFALSE:|avg_intake_|TRUE$") %>%
        str_replace("empiricalTRUE:", "abx * ") %>%
        str_replace_all("_", " ")
    )

  # Separate into two dataframes for two separate plots
  main_effects_df <- cleaned_effects %>% filter(effect_type == "Main Effect")
  interaction_df <- cleaned_effects %>% filter(effect_type == "Interaction") %>%
    # Create a new column to identify significant results
    # The condition is TRUE if conf.low and conf.high have the same sign (i.e., don't cross zero)
    mutate(is_significant = (conf.low * conf.high) > 0)

  # Plot A: Main Clinical Covariates
  plot_main_effects <- ggplot(main_effects_df, aes(x = estimate, y = fct_reorder(clean_term, estimate))) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
    geom_pointrange(aes(xmin = conf.low, xmax = conf.high), color = "gray50", linewidth = 1, size = 0.7) +
    labs(
      title = str_replace(plot_title, 'avg_intake_','Sweets subgroup: '), # Use the name of the list element as the title
      subtitle = "Main Clinical Effects",
      x = "Coefficient Estimate",
      y = "Covariate"
    ) +
    theme_bw(base_size = 12)

  # Plot B: Food Group Interaction Effects
  plot_interactions <- ggplot(interaction_df, aes(x = estimate, y = fct_reorder(clean_term, estimate))) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
    geom_pointrange(aes(xmin = conf.low, xmax = conf.high, color = is_significant), linewidth = 1, size = 0.7) +
    scale_color_manual(values = c("TRUE" = "red", "FALSE" = "gray50"), guide = "none") +
    labs(
      title = "Food Group Interaction Effects",
      x = "Coefficient Estimate",
      y = "Food Group x Antibiotic Exposure"
    ) +
    theme_bw(base_size = 12) +
    theme(legend.position = "none")

  # Combine the plots and add the overall title for this model's results
  plot_main_effects / plot_interactions + plot_layout(heights = c(1, 2))
}


# --- Step 3: Use purrr::imap to Create a List of Plots ---
# imap iterates through a named list, providing both the data (.x) and the name (.y)
# to the function. This is perfect for creating titled plots.
list_of_ggplots <- imap(all_results, ~create_effects_plot(.x, .y))


# Use patchwork::wrap_plots() to combine all the plots in the list into one image.
# You can specify the number of columns for the layout.
final_composite_plot <- wrap_plots(list_of_ggplots, ncol = 2)

# Use ggsave() to save the combined plot object to a high-resolution file.
ggsave(
  filename = "../data/R27_all_model_effects_comparison.png",
  plot = final_composite_plot,
  width = 12, # Increase width to accommodate multiple plots side-by-side
  height = 13, # Adjust height as needed
  units = "in",
  dpi = 300 # Good resolution for publications
)
```


## tallying exposure to the food codes at different levels 

### exposure , first 2 digits

```{r}
exposure_number2 <- final_model_data %>% 
  # Use summarise() with across() to apply a function to multiple columns
  summarise(
    # The across() function targets all columns that start with "avg_intake_"
    across(
      starts_with("avg_intake_"),
      # For each column, count the number of rows where the value is greater than 0
      # The sum(condition) trick works because TRUE evaluates to 1 and FALSE to 0
      ~ sum(.x > 0, na.rm = TRUE),
      # Create new column names like "n_Nonalcoholic_beverages"
      .names = "n_{.col}"
    )
  ) %>%
  # Optional: Pivot the data into a long format for easier viewing
  pivot_longer(
      cols = everything(),
      names_to = "food_category",
      values_to = "num_stool_exposed_to_any_intake"
  ) %>%
  # Clean up the names for the final table
  mutate(food_category = str_remove(food_category, "n_avg_intake_")) %>% 
  inner_join(level2,  by = c(  "food_category" = "f2_desc")) %>% 
  rename(food_code = f2_code) %>% 
  mutate(level = "2-Digit Subcategories")


# Print the resulting summary table
print(exposure_number2)
```

### exposure , first 3 digits  

```{r}
# This pipe creates a tidy summary of daily intake per category.
daily_intake_summary <- dtb %>%
  # Ensures Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%
  # Create a temporary key column with the first 3 digits of the Food_code
  mutate(f3_code_prefix = str_sub(Food_code, 1, 3)) %>%
  
  # Join our lookup table to the main data to get the f3_desc for each food item
  left_join(level3, by = c("f3_code_prefix" = "f3_code")) %>%
  
  # Now, create the final food category based on the other main groups,
  # using the f3_desc as the category name for the sweets and beverages.
  mutate(
    food_category = case_when(
      # If f3_desc is not NA, use it as the category.
      # This handles all your 9xx codes automatically.
      !is.na(f3_desc) ~ f3_desc,
      TRUE ~ NA_character_
    )
  ) %>%
  # Removes any rows that were not assigned to a category
  filter(!is.na(food_category)) %>%
  # Groups the data to sum up weights for each category within a patient-day
  group_by(pid, fdrt, food_category) %>%
  # Calculates the total dehydrated weight for each group
  summarise(
    total_dehydrated_weight = sum(dehydrated_weight, na.rm = TRUE),
    .groups = 'drop'
  )

# --- Part 2: Calculate 2-Day Prior Average Intake for Each Stool Sample ---

# Create helper columns for the time window.
stool_samples_with_window <- stool_samples_df %>%
  mutate(
    window_start = sdrt - 2,
    window_end = sdrt - 1
  )

# Perform the join and calculate the averages.
final_model_data_first3 <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # Reshape the data into the final wide format needed for modeling.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_intake_" # Adds a clear prefix to the new columns
  ) %>%
  # This divides all the new intake columns by 100 for easier model interpretation.
  mutate(across(starts_with("avg_intake_"), ~ .x / 100)) 


# tally
exposure_number3 <- final_model_data_first3 %>% 
  # Use summarise() with across() to apply a function to multiple columns
  summarise(
    # The across() function targets all columns that start with "avg_intake_"
    across(
      starts_with("avg_intake_"),
      # For each column, count the number of rows where the value is greater than 0
      # The sum(condition) trick works because TRUE evaluates to 1 and FALSE to 0
      ~ sum(.x > 0, na.rm = TRUE),
      # Create new column names like "n_Nonalcoholic_beverages"
      .names = "n_{.col}"
    )
  ) %>%
  pivot_longer(
      cols = everything(),
      names_to = "food_category",
      values_to = "num_stool_exposed_to_any_intake"
  ) %>%
  # Clean up the names for the final table
  mutate(food_category = str_remove(food_category, "n_avg_intake_")) %>% 
  filter(food_category != 'NA') %>% 
  inner_join(level3,  by = c(  "food_category" = "f3_desc")) %>% 
  rename(food_code = f3_code) %>% 
  mutate(level = "3-Digit Subcategories")


# Print the resulting summary table
print(exposure_number3)

```


```{r}
# annotate N samples from N patients exposed for each of the four groups
# when you tally up the N exposed samples from N pateints for each of the two-digit codes, would you also please tally up the same exposure numbers for 3-digit and 4-digit codes within the 9xxxxxxx category? I want to get a sense of how statistical power will diminish as we get further and further refined, and if there is a steep drop off, we might be able to use that to justify only analyzing to the second digit and not, say, the 3rd or 4th digit

```

### exposure , first 4 digits  

```{r}
# This pipe creates a tidy summary of daily intake per category.
daily_intake_summary <- dtb %>%
  # Ensures Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%
  mutate(f4_code_prefix = str_sub(Food_code, 1, 4)) %>%
  
  left_join(sweets4, by = c("f4_code_prefix" = "Level.code")) %>%
  
  # Now, create the final food category based on the other main groups,
  mutate(
    food_category = case_when(

      !is.na(Main.food.description) ~ Main.food.description,
      TRUE ~ NA_character_
    )
  ) %>%
  # Removes any rows that were not assigned to a category
  filter(!is.na(food_category)) %>%
  # Groups the data to sum up weights for each category within a patient-day
  group_by(pid, fdrt, food_category) %>%
  # Calculates the total dehydrated weight for each group
  summarise(
    total_dehydrated_weight = sum(dehydrated_weight, na.rm = TRUE),
    .groups = 'drop'
  )

# --- Part 2: Calculate 2-Day Prior Average Intake for Each Stool Sample ---

# Create helper columns for the time window.
stool_samples_with_window <- stool_samples_df %>%
  mutate(
    window_start = sdrt - 2,
    window_end = sdrt - 1
  )

# Perform the join and calculate the averages.
final_model_data_first4 <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # Reshape the data into the final wide format needed for modeling.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_intake_" # Adds a clear prefix to the new columns
  ) %>%
  # This divides all the new intake columns by 100 for easier model interpretation.
  mutate(across(starts_with("avg_intake_"), ~ .x / 100)) 


# tally
exposure_number4 <- final_model_data_first4 %>% 
  # Use summarise() with across() to apply a function to multiple columns
  summarise(
    # The across() function targets all columns that start with "avg_intake_"
    across(
      starts_with("avg_intake_"),
      # For each column, count the number of rows where the value is greater than 0
      # The sum(condition) trick works because TRUE evaluates to 1 and FALSE to 0
      ~ sum(.x > 0, na.rm = TRUE),
      # Create new column names like "n_Nonalcoholic_beverages"
      .names = "n_{.col}"
    )
  ) %>%
  pivot_longer(
      cols = everything(),
      names_to = "food_category",
      values_to = "num_stool_exposed_to_any_intake"
  ) %>%
  # Clean up the names for the final table
  mutate(food_category = str_remove(food_category, "n_avg_intake_")) %>% 
  filter(food_category != 'NA') %>% 
  inner_join(sweets4,  by = c(  "food_category" = "Main.food.description")) %>% 
  rename(food_code = Level.code) %>% 
  mutate(level = "4-Digit Subcategories")


# Print the resulting summary table
print(exposure_number4)

```

### visualize   

```{r}
library(treemapify) # For creating treemaps with ggplot

# Combine all three dataframes into a single one
combined_data <- bind_rows(exposure_number2, exposure_number3, exposure_number4) %>%
  # Create a label for the plot that includes the code, description, and sample size (N)
  mutate(
    plot_label = paste0(food_code, "\n", food_category, "\n(N = ", num_stool_exposed_to_any_intake, ")")
  )

# --- Step 3: Create the Treemap Visualization ---

ggplot(combined_data, aes(area = num_stool_exposed_to_any_intake, fill = food_code, label = plot_label)) +
  # geom_treemap creates the rectangles, where the area is proportional to the sample size
  geom_treemap() +
  # geom_treemap_text adds the labels inside the rectangles
  geom_treemap_text(
    color = "white",
    place = "centre", # Center the text
    grow = TRUE,      # Allow text to grow to fill the box
    min.size = 8      # Don't show text in very small boxes
  ) +
  # Use facet_wrap to create a separate plot for each level of granularity
  facet_wrap(~ factor(level, levels = c("2-Digit Subcategories", "3-Digit Subcategories", "4-Digit Subcategories"))) +
  # Add informative labels and a title
  labs(
    title = "Decrease in Statistical Power with Increasing Food Code Granularity",
    subtitle = "Area of each box is proportional to the number of exposed stool samples (N)"
  ) +
  # Use a clean theme and remove the legend as the labels are on the plot
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12),
    strip.text = element_text(size = 14, face = "bold") # Style the facet titles
  )

ggsave('../data/R27_decreasing_power.pdf', width = 28)

```


```{r}
# Plot B: Bar chart of sugar proportion
sugar_plot <- ggplot(summary_stats, aes(x = sugar_proportion, y = fct_reorder(label, estimate))) +
  geom_col(aes(fill = sugar_proportion), show.legend = FALSE) +
  # Add text labels showing the exact percentage
  geom_text(aes(label = scales::percent(sugar_proportion, accuracy = 1)), hjust = -0.2, size = 3.5) +
  scale_x_continuous(labels = scales::percent, limits = c(0, 1), expand = expansion(mult = c(0, 0.15))) +
  scale_fill_gradient(low = "#FFD166", high = "#FF6B6B") +
  labs(
    title = "B) Sugar Content",
    subtitle = "% of dry weight from sugar",
    x = "Sugar Proportion",
    y = "" # No y-axis label needed as it aligns with Plot A
  ) +
  theme_bw(base_size = 12) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

sugar_plot
```
```{r}
library(patchwork)
# Use patchwork to arrange the plots side-by-side
combined_plot <- forest_plot + sugar_plot

print(combined_plot)

```
# make a tree showing the first three digit level of the sweets group that showed up in this dataset 

```{r}
# manually create the 953 that has the Sports_drinks/Fluid_replacements
level3 <-  read_tsv('../data/NodeLabelsMCT_modified953.txt', col_types = 'cc')  %>%  
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 3) %>% 
  rename(f3_code = Level.code, f3_desc = Main.food.description)


level2 <-  read_tsv('../data/NodeLabelsMCT_modified953.txt', col_types = 'cc')  %>%  
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 2) %>% 
  rename(f2_code = Level.code, f2_desc = Main.food.description)


# what are the food codes that exist in this data set 
fndds_structure_table <- dtb_ %>%  
  mutate(Food_code = as.character(Food_code)) %>%
  filter(str_detect(Food_code, '^9')) %>% 
  distinct(Food_code) %>% 
  mutate(f2_code = str_sub(Food_code, start = , end = 2),
         f3_code = str_sub(Food_code, start = , end = 3),
         f4_code = str_sub(Food_code, start = , end = 4)) %>% 
  distinct(f3_code, .keep_all = T) %>% 
  left_join(level2) %>% 
  left_join(level3) %>% 
  select(-f4_code)
```
```{r}
library(ape)      # For creating phylogenetic objects
library(ggtree)   # For visualizing trees

# --- Step 2: Convert the Table into a Tree Structure (Newick Format) ---
# This section programmatically builds the text representation of the tree
# that the 'ape' package can understand.

# Create a mapping of code to description for labels
code_to_desc <- bind_rows(
  fndds_structure_table %>% distinct(code = f2_code, desc = f2_desc),
  fndds_structure_table %>% distinct(code = f3_code, desc = f3_desc),
  tibble(code = '9', desc = "Sugars, Sweets, and Beverages")
) %>%
  distinct() %>%
  # Clean up the descriptions for better readability
  mutate(
    desc = str_replace_all(desc, "_", " "),
    desc = str_replace(desc, "sugarsugar", "sugar"),
    desc = str_replace(desc, "energy drinks sport.+$", "etc.")
  ) %>%
  mutate(label = paste(code, desc, sep = ": "))

```
```{r}
# Create the node data, starting with the tips (level 3)
nodes_l3 <- fndds_structure_table %>%
  distinct(code = f3_code, parent = f2_code) %>%
  arrange(parent, code) %>%
  mutate(y = row_number(), x = 2.0) # Level 3 nodes are at x=2.0

# Calculate positions for level 2 nodes by centering them over their children
nodes_l2 <- nodes_l3 %>%
  group_by(parent) %>%
  summarise(y = mean(y)) %>%
  rename(code = parent) %>%
  mutate(x = 1.5, parent = '9') # Level 2 nodes are at x=1.5

# Calculate position for the root node (level 1) by centering it over its children
nodes_l1 <- nodes_l2 %>%
  summarise(y = mean(y)) %>%
  mutate(x = 1.0, code = '9', parent = NA) # Root node is at x=1.0

# Combine all nodes into one dataframe
all_nodes <- bind_rows(nodes_l1, nodes_l2, nodes_l3) %>%
  mutate(across(c(code, parent), as.character)) %>%
  left_join(code_to_desc, by = c("code" = "code"))

# --- Step 3: Create the Edge Dataframe for Drawing Lines ---
# This creates the vertical and horizontal lines for the tree structure.
edges <- all_nodes %>%
  filter(!is.na(parent)) %>%
  left_join(all_nodes, by = c("parent" = "code"), suffix = c("_child", "_parent")) %>%
  select(x = x_child, y = y_child, xend = x_parent, yend = y_parent)

# --- Step 4: Create the Final Tree Diagram with ggplot2 ---
ggplot() +
  # Draw the horizontal segments of the tree
  geom_segment(data = edges, aes(x = x, y = y, xend = xend + 0.02, yend = y), color = "gray50") +
  # Draw the vertical segments of the tree
  geom_segment(data = edges, aes(x = xend + 0.02, y = y, xend = xend + 0.02, yend = yend), color = "gray50") +

  # Draw the points for each node
  geom_point(data = all_nodes, aes(x = x, y = y, color = factor(x)), size = 2) +
  
  # Draw the text labels, now left-aligned
  geom_text(
    data = all_nodes,
    aes(x = x + 0.05, y = y, label = paste(code, desc, sep = ": ")), # Add a small offset from the point
    hjust = 0,  # Left-align the text
    size = 3.5,
    fontface = "plain"
  ) +
  
  # Define custom colors for each level of the hierarchy
  scale_color_manual(values = c("1" = "#073B4C", "1.5" = "#118AB2", "2" = "#06D6A0"), guide = "none") +
  
  # Reverse the y-axis to have the root at the top and set x-axis limits for a compact view
  scale_y_reverse() +
  scale_x_continuous(limits = c(0.9, 3.5)) +
  
  # Use a minimal theme to remove axes and grids
  theme_void() +
  
  # Add a title
  labs(title = "FNDDS Hierarchy for Sugars, Sweets, and Beverages") +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", margin = margin(b = 20))
  )

ggsave('../data/R27_g9_tree.pdf', width = 12)
```

