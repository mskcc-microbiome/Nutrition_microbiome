---
title: "sub groups of the sweets"
output: html_document
date: "2025-06-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse) 
library(broom.mixed)
library(brms)   
library(ggpubr)
library(patchwork)
library(tidybayes)
library(cowplot)
library(ggridges)
library(brmstools)
library(bayesplot)
library(ggtext)
options(mc.cores = parallel::detectCores())
rstan::rstan_options(auto_write = TRUE)
theme_set(theme_tidybayes() + panel_border())
ncores <- parallel::detectCores()
```

- Major Critiques and Challenges

Lack of Interpretability (The "Black Box" Problem): This is the biggest critique. The model's output can be incredibly difficult to understand. What does the coefficient for "apples" mean after being adjusted for 499 other foods, many of which are highly correlated? The complexity often obscures, rather than clarifies, the biological story.

Extreme Collinearity: Dietary data is notoriously collinear (e.g., people who eat hot dogs often eat hot dog buns). Putting hundreds of correlated food items into one model can make the individual coefficient estimates highly unstable and unreliable. The model may struggle to assign the effect correctly between two highly correlated foods.

Risk of Overfitting: Without very careful and robust regularization, a model with so many predictors is at high risk of "overfitting"â€”finding spurious patterns in the random noise of your specific dataset that will not be reproducible in the future.

It May Be Overkill: If the dominant biological signal comes from a broad nutritional pattern (like high sugar intake), modeling every single food item individually might not provide any more insight than the more logical, hierarchical approach you are taking.

# the sub groups of sweets

```{r}
# what's the subgroup of sweets?    
sweets3 <- read_tsv('../data/NodeLabelsMCT.txt', col_types = 'cc')  %>%  
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 3) 


sweets2 <- read_tsv('../data/NodeLabelsMCT.txt', col_types = 'cc')  %>% 
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 2)      

sweets4 <- read_tsv('../data/NodeLabelsMCT.txt', col_types = 'cc')  %>% 
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 4)      

# manually create the 953 that has the Sports_drinks/Fluid_replacements
level3 <-  read_tsv('../data/NodeLabelsMCT_modified953.txt', col_types = 'cc')  %>%  
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 3) %>% 
  rename(f3_code = Level.code, f3_desc = Main.food.description)


level2 <-  read_tsv('../data/NodeLabelsMCT_modified953.txt', col_types = 'cc')  %>%  
  filter(str_detect(Level.code, '^9')) %>% 
  filter(str_length(Level.code) == 2) %>% 
  rename(f2_code = Level.code, f2_desc = Main.food.description)

dtb  <- read_csv('../data/152_combined_DTB.csv')

# testing the solid and liquid sugar foods association with abx !     
dtb_ <- dtb %>% 
  select(pid, fdrt, Food_NSC, Food_code, dehydrated_weight, Sugars_g) 
```
# 3 broad categories
 
```{r}
daily_intake_summary <- dtb_ %>%

  # Create a new 'food_category' column based on FNDDS codes.
  # The case_when() function checks conditions in order.
  # This is why we put the more specific 3-digit rules before the general 1-digit rules.
  mutate(
    food_category = case_when(
      
      str_starts(Food_code, "91") ~ "Solid_Sweets",
      str_starts(Food_code, "92") | str_starts(Food_code, "95") ~ "Liquid_Sweets",
      str_starts(Food_code, "94") ~ "Water",

      # --- Define the 8 main food categories using the first digit ---
      str_starts(Food_code, "1") ~ "fg_milk",
      str_starts(Food_code, "2") ~ "fg_meat",
      str_starts(Food_code, "3") ~ "fg_egg",
      str_starts(Food_code, "4") ~ "fg_legume",
      str_starts(Food_code, "5") ~ "fg_grain",
      str_starts(Food_code, "6") ~ "fg_fruit",
      str_starts(Food_code, "7") ~ "fg_veggie",
      str_starts(Food_code, "8") ~ "fg_oils",

      # Any food code that doesn't match the rules above will be assigned NA
      TRUE ~ NA_character_
    )
  ) %>%

  # Remove any rows that were not assigned to a category (e.g., ONS, water, etc.)
  filter(!is.na(food_category)) %>%

  # Group the data by patient, day, and our new food category
  group_by(pid, fdrt, food_category) %>%

  # Calculate the total dehydrated weight for each group
  # The na.rm = TRUE argument handles any missing weight values gracefully
  summarise(
    total_dehydrated_weight = sum(dehydrated_weight, na.rm = TRUE),
    total_sugars = sum(Sugars_g, na.rm = TRUE),
    .groups = 'drop' # Ungroup the data after summarizing
  )

# --- View the final summary table ---
# This table is now in a "tidy" format, ready for analysis or plotting.
# Each row shows the total grams of a food category consumed by a patient on a specific day.

# You can also use pivot_wider() to create a "wide" table where each food category
# has its own column. This format is often required for statistical models.
daily_intake_wide <- daily_intake_summary %>%
  pivot_wider(
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fill = 0 # Fill in 0 for categories a patient didn't eat on a given day
  )


# finding the prior two day average of the above groups
stool_samples_df <- read_csv('../data/153_combined_META.csv') %>%
  select(pid, sdrt, sampleid, simpson_reciprocal, empirical, intensity, EN, TPN)

# ---  Calculate the 2-Day Prior Average Intake ---

# This single pipe performs the entire calculation.
# It joins the two tables, filters for the correct time window,
# calculates the average, and reshapes the data into the final format.

stool_samples_with_window <- stool_samples_df %>%
  mutate(
    # The 2-day window starts 2 days before the stool sample...
    window_start = sdrt - 2,
    # ...and ends 1 day before the stool sample.
    window_end = sdrt - 1
  )

# Now, perform the join using these new, pre-calculated columns
final_model_data <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    # The join is performed using direct column comparisons
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # This step reshapes the data into the final wide format needed for modeling.
  # It calculates the average over the 2-day window.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_intake_" # Adds a clear prefix to the new columns
  ) %>%
    # This divides all the new intake columns by 100.
  # The across() function efficiently applies the same operation to many columns.
  mutate(across(starts_with("avg_intake_"), ~ .x / 100)) %>%

  # Joins back the original stool sample info
  right_join(stool_samples_df, by = c("pid", "sdrt")) %>%
  mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left')) %>%
  mutate(intensity = factor(intensity, levels = c('nonablative','reduced','ablative'))) %>%
  mutate(pid = factor(pid))

# repeat the above process but only calculate the prior two day of sugar in those food categories
final_model_sugar <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    # The join is performed using direct column comparisons
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # This step reshapes the data into the final wide format needed for modeling.
  # It calculates the average over the 2-day window.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_sugars,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_sugar_intake_" # Adds a clear prefix to the new columns
  ) %>%
    # This divides all the new intake columns by 100.
  # The across() function efficiently applies the same operation to many columns.
  mutate(across(starts_with("avg_sugar_intake_"), ~ .x / 100)) %>%

  # Joins back the original stool sample info
  right_join(stool_samples_df, by = c("pid", "sdrt")) %>%
  mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left')) %>%
  mutate(intensity = factor(intensity, levels = c('nonablative','reduced','ablative'))) %>%
  mutate(pid = factor(pid))


# iterative modeling
# --- Step 2: Define the food categories for the iterative analysis ---

# Define the "sweets" subcategories that will be swapped in and out of the model
sweets_subcategories_to_test <- c(
  "avg_intake_Solid_Sweets",
  "avg_intake_Liquid_Sweets",
  "avg_intake_Water"
)

# Define the 8 main food groups that will be included as covariates in every model
main_food_groups <- c(
  "avg_intake_fg_milk", "avg_intake_fg_meat", "avg_intake_fg_egg", "avg_intake_fg_legume", "avg_intake_fg_grain",
  "avg_intake_fg_fruit", "avg_intake_fg_veggie", "avg_intake_fg_oils"
)


# --- Step 3: Create a function that runs one iteration of the Bayesian model ---
# This function takes one of the "sweets" subcategory names as input,
# builds the full model formula, sets all priors, runs the model,
# and returns the key results.
run_iterative_model <- function(sweet_variable, data) {

  # Combine the main food groups and the current sweet variable
  all_food_vars <- c(main_food_groups, sweet_variable)

  # Create the interaction terms for all food variables in this iteration
  interaction_terms <- paste(all_food_vars, "empirical", sep = ":")

  # Build the full formula string dynamically
  formula_string <- paste(
    "log(simpson_reciprocal) ~ 0 + intensity + empirical + TPN + EN +",
    paste(interaction_terms, collapse = " + "),
    "+ (1 | pid) + (1 | timebin)"
  )

  # Convert the string to a formula object
  formula <- brms::bf(as.formula(formula_string))

  # Build the priors by adding them together.
  # This single prior() call applies to all coefficients listed in `all_food_coefs`.
  priors <-
    prior(normal(0, 1), class = 'b') + # General prior for all food effects
    # Specific priors that override the general one for non-food covariates
    prior(normal(0, 0.1), class = 'b', coef = "TPNTRUE") +
    prior(normal(0, 0.1), class = 'b', coef = "ENTRUE") +
    prior(normal(0, 0.5), class = 'b', coef = "empiricalTRUE") +
    prior(normal(2, .1), class = 'b', coef = "intensityablative") +
    prior(normal(2, .1), class = 'b', coef = "intensityreduced") +
    prior(normal(2, .1), class = 'b', coef = "intensitynonablative")

  # Fit the model (using fewer iterations for this example to run quickly)
  model_fit <- brm(
    formula = formula,
    data = data,
    prior = priors,
    warmup = 1000, iter = 3000,
    chains = 2, cores = 10, # Adjust cores as needed
    seed = 123,
    silent = 2
  )

  # Tidy the output and return only the interaction term for the sweet subcategory
  tidy(model_fit, conf.int = TRUE) %>%
    filter(term == paste0("empiricalTRUE:", sweet_variable))
}

# --- Step 4: Run the iterative analysis using purrr::map ---
# This will apply the function to each "sweets" subcategory.
# This step will take a significant amount of time to run.
# all_results <- map(
#   sweets_subcategories_to_test,
#   ~run_iterative_model(sweet_variable = .x, data = final_model_data)
# )


```

## the coeff of abx*sugar 

```{r}
#Combine the list of results into a single, clean data frame
comparison_df <- bind_rows(all_results) %>%
  # Clean up the term name to be used as a label
  mutate(food_category = str_remove(term, "empiricalTRUE:")) %>% 
  mutate(is_significant = (conf.low * conf.high) > 0)

comparison_df %>% write_csv('../data/R27_group3_abxsugar_comparison_df.csv')

# Create a forest plot to visualize and compare the effects
forest_plot3 <- ggplot(comparison_df, aes(x = estimate, y = fct_reorder(food_category, -estimate))) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(aes( color = is_significant), size = 4) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high,  color = is_significant), height = 0.2, linewidth = 1) +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "gray50"), guide = "none") +
  labs(
    title = "Interaction Effect of Sweet Subcategories\nwith Antibiotics on Diversity",
    subtitle = "Each estimate is from a separate model\ncontrolling for other main food groups",
    x = "Interaction Coefficient (Effect per 100g intake during antibiotic exposure)",
    y = "Sweet Subcategory"
  ) +
  theme_bw(base_size = 14)

forest_plot3

# defining the orders of the coeff that will be used to plot the total and sugar weight so they align
sub_orders <- comparison_df %>% 
  mutate(food_category = str_replace(food_category,'avg_intake_','')) %>% 
  mutate(food_category = fct_reorder(food_category, -estimate))
sub_orders$food_category
```

## total and sugar dry weight

```{r}
merged_sugar <- final_model_data %>% 
  full_join(final_model_sugar %>% select(pid , sdrt, starts_with("avg_sugar_intake_")))

plot_data <- merged_sugar %>%
  # Select only the columns we need for this plot
  select(pid,sdrt,  starts_with("avg_intake_"), starts_with("avg_sugar_intake_")) %>%
  # Pivot the data from a wide format to a long format
  pivot_longer(
    cols = 3:24,
    names_to = "metric",
    values_to = "grams"
  ) %>%
  #left_join(comparison_df %>% select(metric = food_category , estimate)) %>% 
  # Extract the food category name from the column name
  mutate(
    food_category = str_remove(metric, "avg_intake_|avg_sugar_intake_"),
    metric_type = if_else(str_starts(metric, "avg_sugar_intake_"), "sugar", "total")
  ) %>%
  # only plot the three subcategroes of the sweets group
  filter(food_category %in% c('Liquid_Sweets','Solid_Sweets','Water')) %>% 
  # Reshape again to have total intake and sugar intake in separate columns
  select(pid,sdrt, food_category, metric_type, grams) %>%
  # revert it back to original value by * 100
  mutate(grams = grams * 100) %>% 
  pivot_wider(
    names_from = metric_type,
    values_from = grams
  ) %>%
  # Calculate the overall average intake across all samples for each category
  group_by(food_category) %>%
  summarise(
    avg_total_intake = mean(total, na.rm = TRUE),
    avg_sugar_intake = mean(sugar, na.rm = TRUE)
  ) %>%
  # Calculate the proportion of sugar for sorting purposes
  mutate(
    sugar_proportion = avg_sugar_intake / avg_total_intake
  ) %>%
  # Calculate the non-sugar portion for the stacked bar
  mutate(
    avg_nonsugar_intake = avg_total_intake - avg_sugar_intake
  ) %>%
  # Reshape one last time for easy plotting with ggplot
  pivot_longer(
    cols = c(avg_sugar_intake, avg_nonsugar_intake),
    names_to = "intake_type",
    values_to = "grams"
  ) %>%
  # Clean up names for the plot legend
  mutate(
    intake_type = if_else(intake_type == "avg_sugar_intake", "Sugar", "Non-Sugar Mass"),
    # Clean up food category names for the axis labels
    food_category = str_remove(food_category, "fg_") %>% str_replace_all("_", " "),
    # Reorder the 'food_category' factor based on the sugar proportion
    # The '.desc = TRUE' ensures it's in descending order (highest % at the top)
    food_category = factor(food_category, levels = c('Water','Solid Sweets','Liquid Sweets'))
  ) 

# --- Step 3: Create the Sorted Stacked Bar Chart ---

sugar_plot3 <- ggplot(plot_data, aes(x = grams, y = food_category, fill = intake_type)) +
  # Use geom_col which is an alias for geom_bar(stat="identity")
  geom_col() +
  # Use a color palette that clearly distinguishes sugar
  scale_fill_manual(values = c("Sugar" = "#FF6B6B", "Non-Sugar Mass" = "#BDBDBD")) +
  # Add informative labels
  labs(
    title = "Average Sugar Content by Food Category",
    subtitle = "Categories are sorted by the total consumed mass",
    x = "Average Dehydrated Weight Consumed (grams)",
    y = "Food Category",
    fill = "Component"
  ) +
  # Use a clean theme
  theme_bw() +
  theme(legend.position = "bottom")


combined_plot <- forest_plot3 + sugar_plot3

print(combined_plot)

```


```{r}
# the unsummarized data of all the foods and its sugar

plot_data_all <- merged_sugar %>%
  # Select only the columns we need for this plot
  select(pid,sdrt,  starts_with("avg_intake_"), starts_with("avg_sugar_intake_")) %>%
  # Pivot the data from a wide format to a long format
  pivot_longer(
    cols = 3:24,
    names_to = "metric",
    values_to = "grams"
  ) %>%
  # Extract the food category name from the column name
  mutate(
    food_category = str_remove(metric, "avg_intake_|avg_sugar_intake_"),
    metric_type = if_else(str_starts(metric, "avg_sugar_intake_"), "sugar", "total")
  ) %>%
  # Reshape again to have total intake and sugar intake in separate columns
  select(pid,sdrt, food_category, metric_type, grams) %>%
  # revert it back to original value by * 100
  mutate(grams = grams * 100) %>% 
  pivot_wider(
    names_from = metric_type,
    values_from = grams
  )
```

```{r}
# This plot will show the relationship between total intake and sugar intake
# for each food category in a separate panel.
plot_data_long <- plot_data_all %>%
  pivot_longer(
    cols = c(total, sugar),
    names_to = "intake_type",
    values_to = "grams"
  )

# Calculate a small constant (pseudocount) to add before log transformation
# This prevents errors from taking the log of zero.
pseudocount <- 1e-4

ggplot(plot_data_long, aes(x = sdrt, y = grams + pseudocount, color = intake_type, fill = intake_type)) +
  # Use geom_smooth to show the average trend line and its 95% confidence interval
  # This is the best way to visualize the overall distribution over time.
  geom_smooth(method = "loess", alpha = 0.2) +
  
  # Use a log scale for the y-axis to better visualize the data
  scale_y_log10(labels = scales::label_number(accuracy = 0.1)) +
  annotation_logticks(sides = "l") +
  
  # Manually define colors for clarity
  scale_color_manual(values = c("total" = "black", "sugar" = "red")) +
  scale_fill_manual(values = c("total" = "black", "sugar" = "red")) +
  
  # Create a separate panel for each food category
  facet_wrap(~ food_category) +
  
  # Add informative labels
  labs(
    title = "Distribution of Total vs. Sugar Intake Over Time",
    subtitle = "Lines show the average trend (LOESS smooth) across all patients",
    x = "Days Relative to Transplant (sdrt)",
    y = "Dehydrated Weight (grams, log scale)",
    color = "Intake Type",
    fill = "Intake Type"
  ) +
  # Use a clean theme
  theme_bw() +
  theme(legend.position = "bottom")

```

## find the top foods in the 3 subcategories

```{r}
#  Filter, Summarize, and Prepare Data for Plotting ---

# This data wrangling pipe will isolate the coffee/tea items, find the top
# contributors, and calculate their sugar content for visualization.
sub3_plot_data <- dtb %>%
  # Ensure Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%

  filter(str_starts(Food_code, "91") | str_starts(Food_code, "92") | str_starts(Food_code, "94") | str_starts(Food_code, "95")) %>%
  
  mutate(
    food_category = case_when(
      str_starts(Food_code, "91") ~ "Solid_Sweets",
      str_starts(Food_code, "92") | str_starts(Food_code, "95") ~ "Liquid_Sweets",
      str_starts(Food_code, "94") ~ "Water",
       TRUE ~ NA_character_
    )) %>% 

  # Group by the specific food name to aggregate all consumption records
  group_by(food_category, Food_NSC) %>%

  # Calculate the total intake and total sugar for each specific food item
  summarise(
    total_intake = sum(dehydrated_weight, na.rm = TRUE),
    total_sugar = sum(Sugars_g, na.rm = TRUE)
  ) %>%
  
  # Keep only the top 10 most consumed items for a clean plot
  slice_max(order_by = total_intake, n = 10) %>%

  # Calculate the non-sugar portion for the stacked bar
  mutate(
    non_sugar_mass = total_intake - total_sugar
  ) %>%

  # Reshape the data into a "long" format for easy plotting with ggplot
  pivot_longer(
    cols = c(total_sugar, non_sugar_mass),
    names_to = "component",
    values_to = "grams"
  ) %>%
  # Clean up names for the plot legend
  mutate(
    component = if_else(component == "total_sugar", "Sugar", "Non-Sugar Mass")
  )

# --- Step 3: Create the Stacked Bar Chart ---

ggplot(sub3_plot_data, aes(x = grams, y = fct_reorder(Food_NSC, grams, .fun = sum), fill = component)) +
  # Use geom_col to create the bars
  geom_col() +
  # Use a color palette that clearly distinguishes sugar
  scale_fill_manual(values = c("Sugar" = "#FF6B6B", "Non-Sugar Mass" = "#BDBDBD")) +
  facet_grid(food_category ~ ., scales = 'free_y') +
  # Add informative labels
  labs(
    title = "Top 10 Consumed Items ",
    subtitle = "Showing total intake and the proportion from sugar",
    x = "Total Dehydrated Weight Consumed (grams)",
    y = "Food Item",
    fill = "Component"
  ) +
  # Use a clean theme
  theme_bw() +
  theme(legend.position = "bottom")

ggsave('../data/R27_group3_top10.jpg', height = 7)
```

# the 4 sub-groups     

```{r}
stool_samples_df <- read_csv('../data/153_combined_META.csv') %>%
  select(pid, sdrt, sampleid, simpson_reciprocal, empirical, intensity, EN, TPN)

 
# This pipe creates a tidy summary of daily intake per category.
daily_intake_summary <- dtb %>%
  # Ensures Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%
  # Create a new 'food_category' column based on the FNDDS code prefix.
  # This logic now uses the first two digits for the 9x categories.
  mutate(
    food_category = case_when(
      # --- Rules for the "Sugars, Sweets, and Beverages" major group ---
      str_starts(Food_code, "91") ~ "Sugars_and_sweets",
      str_starts(Food_code, "92") ~ "Nonalcoholic_beverages",
      str_starts(Food_code, "93") ~ "Alcoholic_beverages",
      str_starts(Food_code, "94") ~ "Water",
      str_starts(Food_code, "95") ~ "Formulated_beverages",

      # --- Rules for the other main food groups (using the first digit) ---
      str_starts(Food_code, "1") ~ "fg_milk",
      str_starts(Food_code, "2") ~ "fg_meat",
      str_starts(Food_code, "3") ~ "fg_egg",
      str_starts(Food_code, "4") ~ "fg_legume",
      str_starts(Food_code, "5") ~ "fg_grain",
      str_starts(Food_code, "6") ~ "fg_fruit",
      str_starts(Food_code, "7") ~ "fg_veggie",
      str_starts(Food_code, "8") ~ "fg_oils",
      TRUE ~ NA_character_
    )
  ) %>%
  # Removes any rows that were not assigned to a category
  filter(!is.na(food_category)) %>%
  # Groups the data to sum up weights for each category within a patient-day
  group_by(pid, fdrt, food_category) %>%
  # Calculates the total dehydrated weight for each group
  summarise(
    total_dehydrated_weight = sum(dehydrated_weight, na.rm = TRUE),
     total_sugars = sum(Sugars_g, na.rm = TRUE),
    .groups = 'drop'
  )


# --- Part 2: Calculate 2-Day Prior Average Intake for Each Stool Sample ---

# Create helper columns for the time window.
stool_samples_with_window <- stool_samples_df %>%
  mutate(
    window_start = sdrt - 2,
    window_end = sdrt - 1
  )

# Perform the join and calculate the averages.
final_model_data <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # Reshape the data into the final wide format needed for modeling.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_intake_" # Adds a clear prefix to the new columns
  ) %>%
  # This divides all the new intake columns by 100 for easier model interpretation.
  mutate(across(starts_with("avg_intake_"), ~ .x / 100)) %>%
  # Joins back the original stool sample info.
  right_join(stool_samples_df, by = c("pid", "sdrt")) %>% 
  mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left')) %>% 
  mutate(intensity = factor(intensity, levels = c('nonablative','reduced','ablative'))) %>% 
  mutate(pid = factor(pid)) 


# View the final, model-ready table.
# The columns are now based on the 2-digit FNDDS subgroups.
print(final_model_data)


# repeat the above process but only calculate the prior two day of sugar in those food categories
final_model_sugar <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    # The join is performed using direct column comparisons
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # This step reshapes the data into the final wide format needed for modeling.
  # It calculates the average over the 2-day window.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_sugars,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_sugar_intake_" # Adds a clear prefix to the new columns
  ) %>%
    # This divides all the new intake columns by 100.
  # The across() function efficiently applies the same operation to many columns.
  mutate(across(starts_with("avg_sugar_intake_"), ~ .x / 100)) %>%

  # Joins back the original stool sample info
  right_join(stool_samples_df, by = c("pid", "sdrt")) %>%
  mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left')) %>%
  mutate(intensity = factor(intensity, levels = c('nonablative','reduced','ablative'))) %>%
  mutate(pid = factor(pid))

```
```{r}
# --- Step 2: Define the food categories for the iterative analysis ---

# Define the "sweets" subcategories that will be swapped in and out of the model
sweets_subcategories_to_test <- c(
  "avg_intake_Nonalcoholic_beverages",
  "avg_intake_Sugars_and_sweets",
  "avg_intake_Water",
  "avg_intake_Formulated_beverages"
)

# Define the 8 main food groups that will be included as covariates in every model
main_food_groups <- c(
  "avg_intake_fg_milk", "avg_intake_fg_meat", "avg_intake_fg_egg", "avg_intake_fg_legume", "avg_intake_fg_grain",
  "avg_intake_fg_fruit", "avg_intake_fg_veggie", "avg_intake_fg_oils"
)


# --- Step 3: Create a function that runs one iteration of the Bayesian model ---
# This function takes one of the "sweets" subcategory names as input,
# builds the full model formula, sets all priors, runs the model,
# and returns the key results.
run_iterative_model <- function(sweet_variable, data) {

  # Combine the main food groups and the current sweet variable
  all_food_vars <- c(main_food_groups, sweet_variable)

  # Create the interaction terms for all food variables in this iteration
  interaction_terms <- paste(all_food_vars, "empirical", sep = ":")

  # Build the full formula string dynamically
  formula_string <- paste(
    "log(simpson_reciprocal) ~ 0 + intensity + empirical + TPN + EN +",
    paste(interaction_terms, collapse = " + "),
    "+ (1 | pid) + (1 | timebin)"
  )

  # Convert the string to a formula object
  formula <- brms::bf(as.formula(formula_string))

  # Build the priors by adding them together.
  # This single prior() call applies to all coefficients listed in `all_food_coefs`.
  priors <-
    prior(normal(0, 1), class = 'b') + # General prior for all food effects
    # Specific priors that override the general one for non-food covariates
    prior(normal(0, 0.1), class = 'b', coef = "TPNTRUE") +
    prior(normal(0, 0.1), class = 'b', coef = "ENTRUE") +
    prior(normal(0, 0.5), class = 'b', coef = "empiricalTRUE") +
    prior(normal(2, .1), class = 'b', coef = "intensityablative") +
    prior(normal(2, .1), class = 'b', coef = "intensityreduced") +
    prior(normal(2, .1), class = 'b', coef = "intensitynonablative")

  # Fit the model (using fewer iterations for this example to run quickly)
  model_fit <- brm(
    formula = formula,
    data = data,
    prior = priors,
    warmup = 1000, iter = 3000,
    chains = 2, cores = 10, # Adjust cores as needed
    seed = 123,
    silent = 2
  )

  # Tidy the output and return only the interaction term for the sweet subcategory
  tidy(model_fit, conf.int = TRUE)  # it is the 95% CI by default
}


# --- Step 4: Run the iterative analysis using purrr::map ---
# This will apply the function to each "sweets" subcategory.
# This step will take a significant amount of time to run.
all_results <- map(
  sweets_subcategories_to_test,
  ~run_iterative_model(sweet_variable = .x, data = final_model_data)
)

names(all_results) <- sweets_subcategories_to_test
```

```{r}
# Combine the list of results into a single, clean data frame
all_results %>%
  bind_rows(.id = 'sweets_subcategories_to_test')  %>% write_csv('../data/R27_group4_full_res.csv')

comparison_df <- all_results %>%
  bind_rows(.id = 'sweets_subcategories_to_test') %>% 
  # Clean up the term name to be used as a label
  filter(str_detect(term, 'empiricalTRUE:') & !str_detect(term, 'fg')) %>% 
  mutate(food_category = str_remove(term, "empiricalTRUE:")) %>%
  mutate(food_category = str_remove(food_category, "avg_intake_"))%>% 
  mutate(is_significant = (conf.low * conf.high) > 0)
```

## forest plot

```{r}
# Plot A: Forest plot of model results, annotated with N as a proxy for power
forest_plot4 <- ggplot(comparison_df, aes(x = estimate, y = fct_reorder(food_category, -estimate))) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(aes( color = is_significant), size = 4) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high,  color = is_significant), height = 0.2, linewidth = 1) +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "gray50"), guide = "none") +
  labs(
    title = "Interaction Effect of Sweet Subcategories\nwith Antibiotics on Diversity",
    x = "Interaction Coefficient",
    y = "Food Subcategory"
  ) +
  theme_bw(base_size = 12)

forest_plot4
```

## total and sugar dry weight

```{r}
merged_sugar <- final_model_data %>% 
  full_join(final_model_sugar %>% select(pid , sdrt, starts_with("avg_sugar_intake_")))

plot_data <- merged_sugar %>%
  # Select only the columns we need for this plot
  select(pid,sdrt,  starts_with("avg_intake_"), starts_with("avg_sugar_intake_")) %>%
  # Pivot the data from a wide format to a long format
  pivot_longer(
    cols = 3:26,
    names_to = "metric",
    values_to = "grams"
  ) %>%
  #left_join(comparison_df %>% select(metric = food_category , estimate)) %>% 
  # Extract the food category name from the column name
  mutate(
    food_category = str_remove(metric, "avg_intake_|avg_sugar_intake_"),
    metric_type = if_else(str_starts(metric, "avg_sugar_intake_"), "sugar", "total")
  ) %>%
  # only plot the three subcategroes of the sweets group
  filter(food_category %in% c('Nonalcoholic_beverages','Sugars_and_sweets','Water', 'Formulated_beverages')) %>% 
  # Reshape again to have total intake and sugar intake in separate columns
  select(pid,sdrt, food_category, metric_type, grams) %>%
  # revert it back to original value by * 100
  mutate(grams = grams * 100) %>% 
  pivot_wider(
    names_from = metric_type,
    values_from = grams
  ) %>%
  # Calculate the overall average intake across all samples for each category
  group_by(food_category) %>%
  summarise(
    avg_total_intake = mean(total, na.rm = TRUE),
    avg_sugar_intake = mean(sugar, na.rm = TRUE)
  ) %>%
  # Calculate the proportion of sugar for sorting purposes
  mutate(
    sugar_proportion = avg_sugar_intake / avg_total_intake
  ) %>%
  # Calculate the non-sugar portion for the stacked bar
  mutate(
    avg_nonsugar_intake = avg_total_intake - avg_sugar_intake
  ) %>%
  # Reshape one last time for easy plotting with ggplot
  pivot_longer(
    cols = c(avg_sugar_intake, avg_nonsugar_intake),
    names_to = "intake_type",
    values_to = "grams"
  ) %>%
  # Clean up names for the plot legend
  mutate(
    intake_type = if_else(intake_type == "avg_sugar_intake", "Sugar", "Non-Sugar Mass"),
    # Clean up food category names for the axis labels
    food_category = str_remove(food_category, "fg_") %>% str_replace_all("_", " "),
    # Reorder the 'food_category' factor based on the sugar proportion
    # The '.desc = TRUE' ensures it's in descending order (highest % at the top)
    food_category = factor(food_category, levels = c('Water','Sugars and sweets','Formulated beverages', 'Nonalcoholic beverages'))
  ) 

# --- Step 3: Create the Sorted Stacked Bar Chart ---

sugar_plot4 <- ggplot(plot_data, aes(x = grams, y = food_category, fill = intake_type)) +
  # Use geom_col which is an alias for geom_bar(stat="identity")
  geom_col() +
  # Use a color palette that clearly distinguishes sugar
  scale_fill_manual(values = c("Sugar" = "#FF6B6B", "Non-Sugar Mass" = "#BDBDBD")) +
  # Add informative labels
  labs(
    title = "Average Sugar Content by Food Category",
    subtitle = "Categories are sorted by the total consumed mass",
    x = "Average Dehydrated Weight Consumed (grams)",
    y = "Food Category",
    fill = "Component"
  ) +
  # Use a clean theme
  theme_bw() +
  theme(legend.position = "bottom")


combined_plot <- forest_plot4 + sugar_plot4

print(combined_plot)

```

## top foods 

```{r}
sub4_plot_data <- dtb %>%
  # Ensure Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%

  filter(str_starts(Food_code, "91") | str_starts(Food_code, "92") | str_starts(Food_code, "94") | str_starts(Food_code, "95")) %>%
  
  mutate(
    food_category = case_when(
      str_starts(Food_code, "91") ~ "Sugars_and_sweets",
      str_starts(Food_code, "92") ~ "Nonalcoholic_beverages",
      str_starts(Food_code, "93") ~ "Alcoholic_beverages",
      str_starts(Food_code, "94") ~ "Water",
      str_starts(Food_code, "95") ~ "Formulated_beverages",
       TRUE ~ NA_character_
    )) %>% 

  # Group by the specific food name to aggregate all consumption records
  group_by(food_category, Food_NSC) %>%

  # Calculate the total intake and total sugar for each specific food item
  summarise(
    total_intake = sum(dehydrated_weight, na.rm = TRUE),
    total_sugar = sum(Sugars_g, na.rm = TRUE)
  ) %>%
  
  # Keep only the top 10 most consumed items for a clean plot
  slice_max(order_by = total_intake, n = 10) %>%

  # Calculate the non-sugar portion for the stacked bar
  mutate(
    non_sugar_mass = total_intake - total_sugar
  ) %>%

  # Reshape the data into a "long" format for easy plotting with ggplot
  pivot_longer(
    cols = c(total_sugar, non_sugar_mass),
    names_to = "component",
    values_to = "grams"
  ) %>%
  # Clean up names for the plot legend
  mutate(
    component = if_else(component == "total_sugar", "Sugar", "Non-Sugar Mass")
  )

# --- Step 3: Create the Stacked Bar Chart ---

ggplot(sub4_plot_data, aes(x = grams, y = fct_reorder(Food_NSC, grams, .fun = sum), fill = component)) +
  # Use geom_col to create the bars
  geom_col() +
  # Use a color palette that clearly distinguishes sugar
  scale_fill_manual(values = c("Sugar" = "#FF6B6B", "Non-Sugar Mass" = "#BDBDBD")) +
  facet_grid(food_category ~ ., scales = 'free_y') +
  # Add informative labels
  labs(
    title = "Top 10 Consumed Items ",
    subtitle = "Showing total intake and the proportion from sugar",
    x = "Total Dehydrated Weight Consumed (grams)",
    y = "Food Item",
    fill = "Component"
  ) +
  # Use a clean theme
  theme_bw() +
  theme(legend.position = "bottom")

ggsave('../data/R27_group4_top10.jpg', height = 8, width = 8)
```


## Full bayesian results


```{r}
# --- Step 2: Create a Function to Generate the Plots ---
# This function encapsulates all the cleaning and plotting logic.
# It takes a dataframe of model results and a title string as input.
create_effects_plot <- function(results_df, plot_title) {

  # This pipe filters for the fixed effects and creates clean, human-readable labels.
  cleaned_effects <- results_df %>%
    # Keep only the fixed effects
    filter(effect == "fixed") %>%
    # Create a new column to distinguish main effects from interactions
    mutate(
      effect_type = if_else(str_detect(term, ":"), "Interaction", "Main Effect"),
      # Create clean labels for plotting
      clean_term = term %>%
        str_remove_all("empiricalFALSE:|avg_intake_|TRUE$") %>%
        str_replace("empiricalTRUE:", "abx * ") %>%
        str_replace_all("_", " ")
    )

  # Separate into two dataframes for two separate plots
  main_effects_df <- cleaned_effects %>% filter(effect_type == "Main Effect")
  interaction_df <- cleaned_effects %>% filter(effect_type == "Interaction") %>%
    # Create a new column to identify significant results
    # The condition is TRUE if conf.low and conf.high have the same sign (i.e., don't cross zero)
    mutate(is_significant = (conf.low * conf.high) > 0)

  # Plot A: Main Clinical Covariates
  plot_main_effects <- ggplot(main_effects_df, aes(x = estimate, y = fct_reorder(clean_term, estimate))) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
    geom_pointrange(aes(xmin = conf.low, xmax = conf.high), color = "gray50", linewidth = 1, size = 0.7) +
    labs(
      title = str_replace(plot_title, 'avg_intake_','Sweets subgroup: '), # Use the name of the list element as the title
      subtitle = "Main Clinical Effects",
      x = "Coefficient Estimate",
      y = "Covariate"
    ) +
    theme_bw(base_size = 12)

  # Plot B: Food Group Interaction Effects
  plot_interactions <- ggplot(interaction_df, aes(x = estimate, y = fct_reorder(clean_term, estimate))) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
    geom_pointrange(aes(xmin = conf.low, xmax = conf.high, color = is_significant), linewidth = 1, size = 0.7) +
    scale_color_manual(values = c("TRUE" = "red", "FALSE" = "gray50"), guide = "none") +
    labs(
      title = "Food Group Interaction Effects",
      x = "Coefficient Estimate",
      y = "Food Group x Antibiotic Exposure"
    ) +
    theme_bw(base_size = 12) +
    theme(legend.position = "none")

  # Combine the plots and add the overall title for this model's results
  plot_main_effects / plot_interactions + plot_layout(heights = c(1, 2))
}


# --- Step 3: Use purrr::imap to Create a List of Plots ---
# imap iterates through a named list, providing both the data (.x) and the name (.y)
# to the function. This is perfect for creating titled plots.
list_of_ggplots <- imap(all_results, ~create_effects_plot(.x, .y))


# Use patchwork::wrap_plots() to combine all the plots in the list into one image.
# You can specify the number of columns for the layout.
final_composite_plot <- wrap_plots(list_of_ggplots, ncol = 2)

# Use ggsave() to save the combined plot object to a high-resolution file.
ggsave(
  filename = "../data/R27_all_model_effects_comparison.png",
  plot = final_composite_plot,
  width = 12, # Increase width to accommodate multiple plots side-by-side
  height = 13, # Adjust height as needed
  units = "in",
  dpi = 300 # Good resolution for publications
)
```

 
# tallying exposure to the food codes at different levels 

## first 2 digits

```{r}
level2 <- final_model_data %>% select(starts_with("avg_intake_")) %>% select(!contains('fg')) %>% 
  gather() %>% distinct(key) %>% 
  mutate(food_category = str_remove(key, "avg_intake_")) %>% 
  mutate(food_code = c('92','91','94','95'))

exposure_number2 <- final_model_data %>% 
  # Use summarise() with across() to apply a function to multiple columns
  summarise(
    # The across() function targets all columns that start with "avg_intake_"
    across(
      starts_with("avg_intake_"),
      # For each column, count the number of rows where the value is greater than 0
      # The sum(condition) trick works because TRUE evaluates to 1 and FALSE to 0
      ~ sum(.x > 0, na.rm = TRUE),
      # Create new column names like "n_Nonalcoholic_beverages"
      .names = "n_{.col}"
    )
  ) %>%
  # Optional: Pivot the data into a long format for easier viewing
  pivot_longer(
      cols = everything(),
      names_to = "food_category",
      values_to = "num_stool_exposed_to_any_intake"
  ) %>%
  # Clean up the names for the final table
  mutate(food_category = str_remove(food_category, "n_avg_intake_")) %>% 
  inner_join(level2,  by = "food_category") %>% 
  mutate(level = "2-Digit Subcategories")


# Print the resulting summary table
print(exposure_number2)
```

## first 3 digits  

```{r}
# This pipe creates a tidy summary of daily intake per category.
daily_intake_summary <- dtb %>%
  # Ensures Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%
  # Create a temporary key column with the first 3 digits of the Food_code
  mutate(f3_code_prefix = str_sub(Food_code, 1, 3)) %>%
  
  # Join our lookup table to the main data to get the f3_desc for each food item
  left_join(level3, by = c("f3_code_prefix" = "f3_code")) %>%
  
  # Now, create the final food category based on the other main groups,
  # using the f3_desc as the category name for the sweets and beverages.
  mutate(
    food_category = case_when(
      # If f3_desc is not NA, use it as the category.
      # This handles all your 9xx codes automatically.
      !is.na(f3_desc) ~ f3_desc,
      TRUE ~ NA_character_
    )
  ) %>%
  # Removes any rows that were not assigned to a category
  filter(!is.na(food_category)) %>%
  # Groups the data to sum up weights for each category within a patient-day
  group_by(pid, fdrt, food_category) %>%
  # Calculates the total dehydrated weight for each group
  summarise(
    total_dehydrated_weight = sum(dehydrated_weight, na.rm = TRUE),
    .groups = 'drop'
  )

# --- Part 2: Calculate 2-Day Prior Average Intake for Each Stool Sample ---

# Create helper columns for the time window.
stool_samples_with_window <- stool_samples_df %>%
  mutate(
    window_start = sdrt - 2,
    window_end = sdrt - 1
  )

# Perform the join and calculate the averages.
final_model_data_first3 <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # Reshape the data into the final wide format needed for modeling.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_intake_" # Adds a clear prefix to the new columns
  ) %>%
  # This divides all the new intake columns by 100 for easier model interpretation.
  mutate(across(starts_with("avg_intake_"), ~ .x / 100)) 


# tally
exposure_number3 <- final_model_data_first3 %>% 
  # Use summarise() with across() to apply a function to multiple columns
  summarise(
    # The across() function targets all columns that start with "avg_intake_"
    across(
      starts_with("avg_intake_"),
      # For each column, count the number of rows where the value is greater than 0
      # The sum(condition) trick works because TRUE evaluates to 1 and FALSE to 0
      ~ sum(.x > 0, na.rm = TRUE),
      # Create new column names like "n_Nonalcoholic_beverages"
      .names = "n_{.col}"
    )
  ) %>%
  pivot_longer(
      cols = everything(),
      names_to = "food_category",
      values_to = "num_stool_exposed_to_any_intake"
  ) %>%
  # Clean up the names for the final table
  mutate(food_category = str_remove(food_category, "n_avg_intake_")) %>% 
  filter(food_category != 'NA') %>% 
  inner_join(level3,  by = c(  "food_category" = "f3_desc")) %>% 
  rename(food_code = f3_code) %>% 
  mutate(level = "3-Digit Subcategories")


# Print the resulting summary table
print(exposure_number3)

```



## first 4 digits  

```{r}
# This pipe creates a tidy summary of daily intake per category.
daily_intake_summary <- dtb %>%
  # Ensures Food_code is a character for string matching
  mutate(Food_code = as.character(Food_code)) %>%
  mutate(f4_code_prefix = str_sub(Food_code, 1, 4)) %>%
  
  left_join(sweets4, by = c("f4_code_prefix" = "Level.code")) %>%
  
  # Now, create the final food category based on the other main groups,
  mutate(
    food_category = case_when(

      !is.na(Main.food.description) ~ Main.food.description,
      TRUE ~ NA_character_
    )
  ) %>%
  # Removes any rows that were not assigned to a category
  filter(!is.na(food_category)) %>%
  # Groups the data to sum up weights for each category within a patient-day
  group_by(pid, fdrt, food_category) %>%
  # Calculates the total dehydrated weight for each group
  summarise(
    total_dehydrated_weight = sum(dehydrated_weight, na.rm = TRUE),
    .groups = 'drop'
  )

# --- Part 2: Calculate 2-Day Prior Average Intake for Each Stool Sample ---

# Create helper columns for the time window.
stool_samples_with_window <- stool_samples_df %>%
  mutate(
    window_start = sdrt - 2,
    window_end = sdrt - 1
  )

# Perform the join and calculate the averages.
final_model_data_first4 <- stool_samples_with_window %>%
  left_join(
    daily_intake_summary,
    by = join_by(
      pid,
      window_start <= fdrt,
      window_end >= fdrt
    )
  ) %>%
  # Reshape the data into the final wide format needed for modeling.
  pivot_wider(
    id_cols = c(pid, sdrt), # The columns that identify a unique stool sample
    names_from = food_category,
    values_from = total_dehydrated_weight,
    values_fn = ~ sum(.x, na.rm = TRUE) / 2, # The function to apply: sum and average
    values_fill = 0, # If a category wasn't eaten, its value is 0
    names_prefix = "avg_intake_" # Adds a clear prefix to the new columns
  ) %>%
  # This divides all the new intake columns by 100 for easier model interpretation.
  mutate(across(starts_with("avg_intake_"), ~ .x / 100)) 


# tally
exposure_number4 <- final_model_data_first4 %>% 
  # Use summarise() with across() to apply a function to multiple columns
  summarise(
    # The across() function targets all columns that start with "avg_intake_"
    across(
      starts_with("avg_intake_"),
      # For each column, count the number of rows where the value is greater than 0
      # The sum(condition) trick works because TRUE evaluates to 1 and FALSE to 0
      ~ sum(.x > 0, na.rm = TRUE),
      # Create new column names like "n_Nonalcoholic_beverages"
      .names = "n_{.col}"
    )
  ) %>%
  pivot_longer(
      cols = everything(),
      names_to = "food_category",
      values_to = "num_stool_exposed_to_any_intake"
  ) %>%
  # Clean up the names for the final table
  mutate(food_category = str_remove(food_category, "n_avg_intake_")) %>% 
  filter(food_category != 'NA') %>% 
  inner_join(sweets4,  by = c(  "food_category" = "Main.food.description")) %>% 
  rename(food_code = Level.code) %>% 
  mutate(level = "4-Digit Subcategories")


# Print the resulting summary table
print(exposure_number4)

```

## visualize    

```{r}
# Combine all three dataframes into a single one
combined_data <- bind_rows(exposure_number2, exposure_number3, exposure_number4) %>%
  # Create a label for the plot that includes the code, description, and sample size (N)
  mutate(
    plot_label = paste0(food_code, "\n", food_category, "\n(N = ", num_stool_exposed_to_any_intake, ")")
  )
```


```{r}
library(tidytext)
# --- Step 2: Process the Data for Plotting ---

# This pipe adds a 'parent' category to each subcategory for faceting.
plot_data <- combined_data %>%
  # Clean up the food category descriptions
  mutate(
    description = str_replace_all(food_category, "_", " "),
    plot_label = paste(food_code, description, sep = ": ")
  ) %>%
  # Create a parent code column by taking the first two digits
  mutate(
    parent_code = str_sub(food_code, 1, 2)
  ) %>%
  # Create a lookup table for the parent descriptions
  left_join(
    distinct(filter(., level == "2-Digit Subcategories"), parent_code = food_code, parent_desc = description),
    by = "parent_code"
  ) %>%
 # Use reorder_within to sort categories independently within each facet by sample size (descending)
  mutate(
    category_sorted = reorder_within(plot_label, desc(plot_label), list(level, parent_desc))
  )


# --- Step 3: Create the Faceted Lollipop Plot Visualization ---

ggplot(plot_data, aes(x = num_stool_exposed_to_any_intake, y = category_sorted)) +
  # geom_segment creates the "stick" of the lollipop
  geom_segment(
    aes(x = 0, xend = num_stool_exposed_to_any_intake, y = category_sorted, yend = category_sorted),
    color = "gray"
  ) +
  # geom_point creates the "candy" of the lollipop
  geom_point(aes(color = parent_code), size = 4) +
  
  # This is the key to making the reordering work correctly across facets
  scale_y_reordered() +
  
  # Use facet_grid to create a grid of plots.
  # Rows are faceted by granularity level (3-digit, 4-digit).
  # Columns are faceted by the parent 2-digit category.
  facet_grid(
    factor(level, levels = c('2-Digit Subcategories', "3-Digit Subcategories", "4-Digit Subcategories")) ~ parent_desc,
    scales = "free_y", # Allows each facet to have its own y-axis scale
    space = "free_y"   # Allows each row's height to be proportional to its number of items
  ) +
  
  # Add informative labels and a title
  labs(
    subtitle = "Number of exposed stool samples (N), grouped by parent category",
    x = "Number of Exposed Stool Samples",
    y = "Food Subcategory"
  ) +
  

  theme_bw() +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12),
    strip.text = element_text(size = 10, face = "bold"), # Style the facet titles
    axis.text.y = element_text(size = 8) # Adjust y-axis text size if needed
  )

ggsave('../data/R27_faceted_exposure.jpg', width = 12, height = 9)
```


```{r}
# library(treemapify) # For creating treemaps with ggplot
# 
# # --- Step 3: Create the Treemap Visualization ---
# 
# ggplot(combined_data, aes(area = num_stool_exposed_to_any_intake, fill = food_code, label = plot_label)) +
#   # geom_treemap creates the rectangles, where the area is proportional to the sample size
#   geom_treemap() +
#   # geom_treemap_text adds the labels inside the rectangles
#   geom_treemap_text(
#     color = "white",
#     place = "centre", # Center the text
#     grow = TRUE,      # Allow text to grow to fill the box
#     min.size = 8      # Don't show text in very small boxes
#   ) +
#   # Use facet_wrap to create a separate plot for each level of granularity
#   facet_wrap(~ factor(level, levels = c("2-Digit Subcategories", "3-Digit Subcategories", "4-Digit Subcategories"))) +
#   # Add informative labels and a title
#   labs(
#     title = "Decrease in Statistical Power with Increasing Food Code Granularity",
#     subtitle = "Area of each box is proportional to the number of exposed stool samples (N)"
#   ) +
#   # Use a clean theme and remove the legend as the labels are on the plot
#   theme_minimal() +
#   theme(
#     legend.position = "none",
#     plot.title = element_text(size = 16, face = "bold"),
#     plot.subtitle = element_text(size = 12),
#     strip.text = element_text(size = 14, face = "bold") # Style the facet titles
#   )
# 
# ggsave('../data/R27_decreasing_power.pdf', width = 28)

```



# make a tree showing the first three digit level of the sweets group that showed up in this dataset 

```{r}



# what are the food codes that exist in this data set 
fndds_structure_table <- dtb_ %>%  
  mutate(Food_code = as.character(Food_code)) %>%
  filter(str_detect(Food_code, '^9')) %>% 
  distinct(Food_code) %>% 
  mutate(f2_code = str_sub(Food_code, start = , end = 2),
         f3_code = str_sub(Food_code, start = , end = 3),
         f4_code = str_sub(Food_code, start = , end = 4)) %>% 
  distinct(f3_code, .keep_all = T) %>% 
  left_join(level2) %>% 
  left_join(level3) %>% 
  select(-f4_code)
```
```{r}
library(ape)      # For creating phylogenetic objects
library(ggtree)   # For visualizing trees

# --- Step 2: Convert the Table into a Tree Structure (Newick Format) ---
# This section programmatically builds the text representation of the tree
# that the 'ape' package can understand.

# Create a mapping of code to description for labels
code_to_desc <- bind_rows(
  fndds_structure_table %>% distinct(code = f2_code, desc = f2_desc),
  fndds_structure_table %>% distinct(code = f3_code, desc = f3_desc),
  tibble(code = '9', desc = "Sugars, Sweets, and Beverages")
) %>%
  distinct() %>%
  # Clean up the descriptions for better readability
  mutate(
    desc = str_replace_all(desc, "_", " "),
    desc = str_replace(desc, "sugarsugar", "sugar"),
    desc = str_replace(desc, "energy drinks sport.+$", "etc.")
  ) %>%
  mutate(label = paste(code, desc, sep = ": "))

```
```{r}
# Create the node data, starting with the tips (level 3)
nodes_l3 <- fndds_structure_table %>%
  distinct(code = f3_code, parent = f2_code) %>%
  arrange(parent, code) %>%
  mutate(y = row_number(), x = 2.0) # Level 3 nodes are at x=2.0

# Calculate positions for level 2 nodes by centering them over their children
nodes_l2 <- nodes_l3 %>%
  group_by(parent) %>%
  summarise(y = mean(y)) %>%
  rename(code = parent) %>%
  mutate(x = 1.5, parent = '9') # Level 2 nodes are at x=1.5

# Calculate position for the root node (level 1) by centering it over its children
nodes_l1 <- nodes_l2 %>%
  summarise(y = mean(y)) %>%
  mutate(x = 1.0, code = '9', parent = NA) # Root node is at x=1.0

# Combine all nodes into one dataframe
all_nodes <- bind_rows(nodes_l1, nodes_l2, nodes_l3) %>%
  mutate(across(c(code, parent), as.character)) %>%
  left_join(code_to_desc, by = c("code" = "code"))

# --- Step 3: Create the Edge Dataframe for Drawing Lines ---
# This creates the vertical and horizontal lines for the tree structure.
edges <- all_nodes %>%
  filter(!is.na(parent)) %>%
  left_join(all_nodes, by = c("parent" = "code"), suffix = c("_child", "_parent")) %>%
  select(x = x_child, y = y_child, xend = x_parent, yend = y_parent)

# --- Step 4: Create the Final Tree Diagram with ggplot2 ---
ggplot() +
  # Draw the horizontal segments of the tree
  geom_segment(data = edges, aes(x = x, y = y, xend = xend + 0.02, yend = y), color = "gray50") +
  # Draw the vertical segments of the tree
  geom_segment(data = edges, aes(x = xend + 0.02, y = y, xend = xend + 0.02, yend = yend), color = "gray50") +

  # Draw the points for each node
  geom_point(data = all_nodes, aes(x = x, y = y, color = factor(x)), size = 2) +
  
  # Draw the text labels, now left-aligned
  geom_text(
    data = all_nodes,
    aes(x = x + 0.05, y = y, label = paste(code, desc, sep = ": ")), # Add a small offset from the point
    hjust = 0,  # Left-align the text
    size = 3.5,
    fontface = "plain"
  ) +
  
  # Define custom colors for each level of the hierarchy
  scale_color_manual(values = c("1" = "#073B4C", "1.5" = "#118AB2", "2" = "#06D6A0"), guide = "none") +
  
  # Reverse the y-axis to have the root at the top and set x-axis limits for a compact view
  scale_y_reverse() +
  scale_x_continuous(limits = c(0.9, 3.5)) +
  
  # Use a minimal theme to remove axes and grids
  theme_void() +
  
  # Add a title
  labs(title = "FNDDS Hierarchy for Sugars, Sweets, and Beverages") +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", margin = margin(b = 20))
  )

ggsave('../data/R27_g9_tree.pdf', width = 12)
```

# the pairwise correlation between the 4 subgroups 

```{r}
library(rmcorr)
library(GGally) # Used for its ggpairs-like functionality and themes
library(cowplot) # Used to arrange the final plots

# Replace `your_data` with the name of your actual data frame from this point on.
your_data <- final_model_data

# Step 3: Define the pairs of variables to correlate
food_groups <- c("avg_intake_Nonalcoholic_beverages", "avg_intake_Sugars_and_sweets", "avg_intake_Water", "avg_intake_Formulated_beverages")
pairs_to_calculate <- combn(food_groups, 2, simplify = FALSE)

# Step 4: Create a function to calculate and print the correlation results
# This function will run rmcorr and print a clean summary.
calculate_rmcorr <- function(data, var1, var2) {
  cat("--------------------------------------------------\n")
  cat("Repeated Measures Correlation for:", var1, "and", var2, "\n")
  cat("--------------------------------------------------\n")
  
  # Create the function call by substituting placeholders (v1, v2)
  # with the actual variable names from our strings (var1, var2).
  the_call <- substitute(
    rmcorr(participant = pid, measure1 = v1, measure2 = v2, dataset = data),
    list(v1 = as.name(var1), v2 = as.name(var2))
  )
  
  # Evaluate the fully formed call.
  rmcorr_result <- eval(the_call)

  # Return a tidy tibble with the results
  tibble(
    var1 = var1,
    var2 = var2,
    r = rmcorr_result$r,
    p.value = rmcorr_result$p
  )
}

# so there is actually no correlation, which is not surprising. 

# Step 5: Run the calculation for each pair and combine into a single data frame
# Get all combinations of the food groups
all_pairs <- combn(food_groups, 2, simplify = FALSE)

# Calculate correlations for all pairs
corr_results <- map_dfr(all_pairs, ~calculate_rmcorr(your_data, .x[1], .x[2]))
```
```{r}
# look at all of the pairwise correlation of the food groups 
all_food_vars <- final_model_data %>% select(starts_with('avg')) %>% colnames()

pairs_to_calculate_all <- combn(all_food_vars, 2, simplify = FALSE)

# Calculate correlations for all pairs
corr_results_all <- map_dfr(pairs_to_calculate_all, ~calculate_rmcorr(final_model_data, .x[1], .x[2]))

plot_data <- corr_results_all %>%
  mutate(
    neg_log10_p = -log10(p.value)
  ) %>%
  # To make the plot symmetrical, we add the reverse pairs
  bind_rows(
    corr_results_all %>%
      rename(var1_temp = var1) %>% 
      rename(var1 = var2) %>%
      rename(var2 = var1_temp) %>% 
      mutate(neg_log10_p = -log10(p.value))
  )

# Step 7: Visualize the correlations as a scatter plot (bubble plot)
correlation_bubble_plot <- ggplot(plot_data, aes(x = var1, y = var2)) +
  # Use geom_point to create the scatter plot
  geom_point(aes(color = r, size = neg_log10_p), alpha = 0.8) +
  # Use a diverging color scale for the correlation values (r)
  scale_color_gradient2(low = "#075AFF", high = "#FF0000", mid = "white",
                        midpoint = 0, limit = c(-1,1), name = "Correlation (r)") +
  # Control the size of the points based on significance
  scale_size_continuous(name = "Significance (-log10 p-value)", range = c(2, 10)) +
  # Use a minimal theme
  theme_minimal(base_size = 12) +
  # Clean up the theme for a publication-ready look
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
    axis.title = element_blank(),
    panel.grid.major = element_line(color = "grey90"),
    legend.position = "right"
  ) +
  labs(
    title = "Pairwise Repeated Measures Correlations",
    subtitle = "Point size represents statistical significance, color represents correlation strength"
  )

# Print the plot
print(correlation_bubble_plot)

```

```{r}
# the above plot but the plot each pair correlation as bars, and the bar height corresponding to the r, and the fill corresponding to the neg_log10_p, sorted by the r in the descending order 
plot_data <- corr_results_all %>%
  mutate(
    neg_log10_p = -log10(p.value),
    # Create a descriptive label for each pair
    pair_label = paste(var1, "&", var2),
    # Reorder the labels based on the correlation coefficient 'r' in descending order
    pair_label_sorted = fct_reorder(pair_label, r, .desc = TRUE)
  )

# Step 7: Visualize the correlations as a sorted bar plot
correlation_bar_plot <- ggplot(plot_data, aes(x = pair_label_sorted, y = r, fill = neg_log10_p)) +
  geom_col(color = "black", linewidth = 0.5) + # Use geom_col for bar plot where height is specified
  # Add text labels for the r-value on top of each bar
  geom_text(aes(label = sprintf("%.2f", r)), hjust = -0.2, size = 3.5) +
  # Flip coordinates to make bars horizontal for better readability of labels
  coord_flip(ylim = c(min(plot_data$r) - 0.1, max(plot_data$r) + 0.1)) +
  # Use a sequential color scale for the fill (significance)
  scale_fill_viridis_c(name = "Significance\n(-log10 p-value)", option = "C") +
  # Add a horizontal line at y=0 for reference
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey50") +
  labs(
    title = "Pairwise Repeated Measures Correlations",
    subtitle = "Bar length represents correlation strength (r), color represents significance",
    x = "Food Group Pair",
    y = "Repeated Measures Correlation (r)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
      panel.grid.major.y = element_blank(), # Remove horizontal grid lines
      panel.grid.minor.x = element_blank(), # Remove vertical minor grid lines
      axis.title.x = element_text(margin = margin(t = 10)),
      plot.title = element_text(face = "bold")
  )

# Print the plot
print(correlation_bar_plot)
```

```{r}
# Step 7: Visualize the correlation matrix as a heatmap
correlation_heatmap <- ggplot(corr_results %>% mutate(r = round(r, digits = 2)), aes(x = var1, y = var2, fill = r)) +
  geom_tile(color = "black", linewidth = 0.2) +
  # Add the correlation coefficient text to the tiles
  geom_text(aes(label = r), color = "black", size = 2) +
  # Use a diverging color scale for the correlation values
  scale_fill_gradient2(low = "#075AFF", high = "#FF0000", mid = "yellow",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Repeated Measures\nCorrelation (r)") +
  theme_minimal(base_size = 12) +
  # Clean up the theme for a publication-ready look
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, size = 10, hjust = 1),
    axis.title = element_blank(),
    panel.grid.major = element_blank(),
    legend.position = "top",
    legend.justification = "center"
  ) +
  guides(fill = guide_colorbar(barwidth = 10, barheight = 1.5,
                               title.position = "top", title.hjust = 0.5)) +
  coord_fixed() + # Ensure tiles are square
  labs(
    title = "Pairwise Repeated Measures Correlation Matrix"
    )

# Print the plot
print(correlation_heatmap)
```
```{r}
# Load the required library
library(corrplot)

# --- Manually Create the Correlation Matrix from Your Results ---
# Instead of calculating correlations from raw data, we'll build the
# matrix directly from the 'r' values in your screenshot.

# Define the variable names for clarity
var_names <- c(
  "Nonalcoholic_beverages",
  "Sugars_and_sweets",
  "Water",
  "Formulated_beverages"
)

# Create the matrix of correlation coefficients ('r' values)
# The matrix is filled by row. The diagonal is 1 (correlation with self).
# The lower triangle mirrors the upper triangle.
cor_matrix <- matrix(c(
  1.000,   0.050,  -0.097,  -0.058,  # Row for Nonalcoholic
  0.050,   1.000,   0.007,  -0.026,  # Row for Sugars
 -0.097,   0.007,   1.000,  -0.000,  # Row for Water
 -0.058,  -0.026,  -0.000,   1.000   # Row for Formulated
), nrow = 4, ncol = 4, byrow = TRUE, dimnames = list(var_names, var_names))


# --- Create the Matrix of P-values ---
# This matrix corresponds to the correlation matrix and will be used
# to identify and visualize significant correlations.
p_matrix <- matrix(c(
  0.000,   0.146,   0.005,   0.091,  # P-values for Nonalcoholic
  0.146,   0.000,   0.845,   0.457,  # P-values for Sugars
  0.005,   0.845,   0.000,   0.989,  # P-values for Water
  0.091,   0.457,   0.989,   0.000   # P-values for Formulated
), nrow = 4, ncol = 4, byrow = TRUE, dimnames = list(var_names, var_names))


# --- Generate the Visualizations ---

# Set up the plotting area to show multiple plots
par(mfrow = c(1, 2)) # Arrange plots in 1 row and 2 columns

# --- Plot 1: Mixed Visualization (Pies & Numbers) ---
# This version combines numbers in the lower triangle with pie charts
# in the upper triangle. The pie fill represents the correlation strength.
corrplot.mixed(cor_matrix,
               lower.col = "black",
               number.cex = 0.9,
               upper = "pie",
               tl.col = "black",
               tl.srt = 45,
               title = "Mixed Correlogram",
               mar=c(0,0,1,0))


# --- Plot 2: Highlighting Significant Correlations ---
# This plot displays all coefficients but visually marks the non-significant
# ones with a cross. This is a very common and effective technique.
# We use the p-value matrix to determine significance (p < 0.05).
corrplot(cor_matrix,
         p.mat = p_matrix,
         method = "circle",
         type = "lower",
         insig = "p-value", # Show p-values for non-significant results
         sig.level = 0.05,  # Set the significance level
         pch.cex = 0.9,     # Size of the p-value text
         tl.col = "black",
         tl.srt = 45,
         addCoef.col = "black",
         diag = FALSE,
         title = "Significant Correlations (p < 0.05)",
         mar=c(0,0,1,0))

# Reset plotting area to default
par(mfrow = c(1, 1))


```

# 4 subgroups together

```{r}
all_food_vars <- final_model_data %>% select(starts_with('avg')) %>% colnames()

# Create the interaction terms for all food variables in this iteration
interaction_terms <- paste(all_food_vars, "empirical", sep = ":")

# Build the full formula string dynamically
formula_string <- paste(
  "log(simpson_reciprocal) ~ 0 + intensity + empirical + TPN + EN +",
  paste(interaction_terms, collapse = " + "),
  "+ (1 | pid) + (1 | timebin)"
)

# Convert the string to a formula object
formula <- brms::bf(as.formula(formula_string))

# Build the priors by adding them together.
# This single prior() call applies to all coefficients listed in `all_food_coefs`.
priors <-
    prior(normal(0, 1), class = 'b') + # General prior for all food effects
    # Specific priors that override the general one for non-food covariates
    prior(normal(0, 0.1), class = 'b', coef = "TPNTRUE") +
    prior(normal(0, 0.1), class = 'b', coef = "ENTRUE") +
    prior(normal(0, 0.5), class = 'b', coef = "empiricalTRUE") +
    prior(normal(2, .1), class = 'b', coef = "intensityablative") +
    prior(normal(2, .1), class = 'b', coef = "intensityreduced") +
    prior(normal(2, .1), class = 'b', coef = "intensitynonablative")

# Fit the model (using fewer iterations for this example to run quickly)
model_fit <- brm(
  formula = formula,
  data = final_model_data,
  prior = priors,
    warmup = 1000, iter = 3000,
    chains = 2, cores = 10,
    seed = 123,
    silent = 2
)

results_df <- tidy(model_fit, conf.int = TRUE) %>% 
  mutate(conf.low = round(conf.low, 2),
         conf.high = round(conf.high, 2))
```
```{r}
cleaned_effects <- results_df %>%
  # Keep only the fixed effects
  filter(effect == "fixed") %>%
  # Create a new column to distinguish main effects from interactions
  mutate(
    effect_type = if_else(str_detect(term, ":"), "Interaction", "Main Effect"),
    # Create clean labels for plotting
    clean_term = term %>%
      str_remove_all("empiricalFALSE:|avg_intake_|TRUE$") %>%
      str_replace("empiricalTRUE:", "abx * ") %>%
      str_replace_all("_", " ")
  )

# Separate into two dataframes for two separate plots
main_effects_df <- cleaned_effects %>% filter(effect_type == "Main Effect")
interaction_df <- cleaned_effects %>% filter(effect_type == "Interaction") %>%
  # Create a new column to identify significant results
  # The condition is TRUE if conf.low and conf.high have the same sign (i.e., don't cross zero)
  mutate(is_significant = (conf.low * conf.high) >= 0)

# Plot A: Main Clinical Covariates
plot_main_effects <- ggplot(main_effects_df, aes(x = estimate, y = fct_reorder(clean_term, estimate))) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  geom_pointrange(aes(xmin = conf.low, xmax = conf.high), color = "gray50", linewidth = 1, size = 0.7) +
  labs(
    title = '', # Use the name of the list element as the title
    subtitle = "Main Clinical Effects",
    x = "Coefficient Estimate",
    y = "Covariate"
  ) +
  theme_bw(base_size = 12)

# This pipe creates clean labels and adds a special 'highlight' column
interaction_df_processed <- interaction_df %>%
  # Create a column to flag the specific term you want to highlight
  mutate(
    highlight_status = case_when(
      #clean_term == "abx * fg sweets" ~ "Of Interest",
      is_significant == TRUE    ~ "Significant",
      TRUE                      ~ "Not Significant"
    )
  )

# --- Step 3: Create the Visualization ---

plot_interactions <- ggplot(interaction_df_processed, aes(x = estimate, y = fct_reorder(clean_term, estimate))) +
  # Add a vertical line at zero, which represents "no effect"
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  
  # Use geom_pointrange to show the estimate (point) and confidence interval (line)
  # The color and alpha (transparency) are now mapped to our new 'highlight_status' column
  geom_pointrange(
    aes(xmin = conf.low, xmax = conf.high, color = highlight_status, alpha = highlight_status),
    linewidth = 1, size = 0.7
  ) +
  
  # Manually define the colors and alpha levels for each status
  scale_color_manual(
    values = c(
      "Significant" = "red",
     # "Of Interest" = "blue",
      "Not Significant" = "gray50"
    ),
    name = "Effect Status" # Legend title
  ) +
  scale_alpha_manual(
    values = c(
      "Significant" = 1.0, # Fully opaque
      "Of Interest" = 1.0, # Fully opaque
      "Not Significant" = 1.0  # More transparent
    ),
    guide = "none" # Hide the separate alpha legend
  ) +
  
  # Add labels and a clean theme
  labs(
    title = "Interaction Effect of food groups\nwith Antibiotics on Diversity",
    x = "Interaction Coefficient",
    y = "Food Group x Antibiotic Exposure"
  ) +
  theme_bw(base_size = 14) +
  theme(legend.position = "bottom")


# Combine the plots and add the overall title for this model's results
plot_main_effects / plot_interactions + plot_layout(heights = c(1, 2))
```
## figure 

```{r}
# the above figure but make it the way the other figure look like 
key <- read_csv('../data/food_group_color_key_final.csv', col_types = 'ccccc')

replacement_dictionary <- setNames(key$shortname, key$fg1_name)

level_order <- rev(c(
    "abx", "EN", "TPN",
    "abx * Formulated beverages", "Formulated beverages",
    "abx * Nonalcoholic beverages", "Nonalcoholic beverages",
    "abx * Sugars and sweets", "Sugars and sweets", # Note: 'Sugars and sweets' becomes 'Sweets'
    "abx * Water", "Water",
    "abx * Grains", "Grains",
    "abx * Milk", "Milk",
    "abx * Eggs", "Eggs",
    "abx * Legumes", "Legumes",
    "abx * Meats", "Meats",
    "abx * Fruits", "Fruits",
    "abx * Oils", "Oils",
    "abx * Vegetables", "Vegetables"
))

cleaned_effects <- results_df %>%
  # Keep only the fixed effects
  filter(effect == "fixed") %>%
  # Create a new column to distinguish main effects from interactions
  mutate(
    effect_type = if_else(str_detect(term, ":"), "Interaction", "Main Effect"),
    # Create clean labels for plotting
    clean_term = term %>%
      str_replace("empiricalTRUE$", "abx") %>%
      str_remove_all("empiricalFALSE:|avg_intake_|TRUE$") %>%
      str_replace_all( replacement_dictionary) %>% 
      str_replace("empiricalTRUE:", "abx * ") %>%
      str_replace_all("_", " ")
  ) %>% 
  filter(!str_detect(clean_term, 'intensity')) %>%
  # Create a new column to identify significant results
  # The condition is TRUE if conf.low and conf.high have the same sign (i.e., don't cross zero)
  mutate(is_significant = (conf.low * conf.high) >= 0) %>% 
  mutate(clean_term = factor(clean_term, levels = level_order))

shading_df <- cleaned_effects %>%
  mutate(y_numeric = as.numeric(clean_term)) %>%
  filter(str_detect(clean_term, "\\*")) # Filter for interaction terms

plot_subsweets <- ggplot(cleaned_effects, aes(x = estimate, y = clean_term)) +
  geom_rect(
    data = shading_df,
    aes(ymin = y_numeric - 0.5, ymax = y_numeric + 0.5, xmin = -Inf, xmax = Inf),
    fill = "#FBEADC", # A light orange/peach color like the example
    alpha = 0.7,
    inherit.aes = FALSE
   ) +
   # Add a vertical line at zero, which represents "no effect"
  geom_vline(xintercept = 0, linetype = "solid", color = "blue",size = 0.8) +
   # Use geom_pointrange to show the estimate (point) and confidence interval (line)
   geom_pointrange(
   aes(xmin = conf.low, xmax = conf.high, color = is_significant),
     size = 0.25,linewidth = 1,
  ) +
  scale_color_manual(
    values = c(
      "TRUE" = "red",
      "FALSE" = "black"
    ), name = "Effect Status" # Legend title
  ) +
  scale_y_discrete( labels = function(x) { ifelse(str_detect(x, '\\*'),  str_glue("<b style='color:royalblue'>{x}</b>"), as.character(x)) }) +
  # Add labels and a clean theme
  labs(
    x = "ln(diversity) change",
    y = ""
  ) +
  theme_classic(base_size = 11) +
  theme(legend.position = "none", axis.text.y = element_markdown())
  
plot_subsweets  
```

