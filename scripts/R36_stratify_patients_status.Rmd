---
title: "Stratification by patient status"
output: html_document
date: "2025-08-04"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(broom.mixed)
library(brms)   
library(ggpubr)
library(patchwork)
library(tidybayes)
library(cowplot)
library(ggridges)
library(brmstools)
library(bayesplot)
options(mc.cores = parallel::detectCores())
rstan::rstan_options(auto_write = TRUE)
theme_set(theme_tidybayes() + panel_border())
ncores <- parallel::detectCores()
```
- Why Not to Split the Data     
  
- Loss of Power

- Wasted Information: The model learns about the general effects of diet and antibiotics from the entire cohort. By splitting the data, you prevent the model from "borrowing strength" across the groups, making your estimates less precise.

- No Direct Comparison: Running three separate models doesn't actually give you a statistical test to say whether the effect of sweets * abx is significantly different between the ablative and non-ablative groups.

# run three way interaction model

I am testing if the effect of sweets * abx depends on the intensity level. In statistical terms, you are testing for an interaction between (sweets * abx) and intensity.

```{r}
meta <- read_csv('../data/153_combined_META.csv')
```


```{r}
# Combine the main food groups and the current sweet variable
other_food_terms <- meta %>% select(starts_with('fg')) %>% select(-fg_sweets) %>% colnames()

other_food_terms_ <- paste(other_food_terms, collapse = ' + ')

sweet_interaction_term <- 'fg_sweets * empirical * intensity'

all_terms <- paste(other_food_terms_, sweet_interaction_term, sep =  ' + ')

# Build the full formula string dynamically
formula_string <- paste(
  "log(simpson_reciprocal) ~ 0   + TPN + EN +",
  all_terms,
  "+ (1 | pid) + (1 | timebin)"
)

# Convert the string to a formula object
formula <- brms::bf(as.formula(formula_string))

# Build the priors by adding them together.
# This single prior() call applies to all coefficients listed in `all_food_coefs`.
priors <-
  prior(normal(0, 1), class = 'b') + # General prior for all food effects
  # Specific priors that override the general one for non-food covariates
  prior(normal(0, 0.1), class = 'b', coef = "TPNTRUE") +
  prior(normal(0, 0.1), class = 'b', coef = "ENTRUE") +
  prior(normal(0, 0.5), class = 'b', coef = "empiricalTRUE") 

# Fit the model (using fewer iterations for this example to run quickly)
model_fit <- brm(
  formula = formula,
  data = meta,
  prior = priors,
  warmup = 1000, iter = 3000,
  chains = 2, cores = 10, # Adjust cores as needed
  seed = 123,
  silent = 2
)

# Tidy the output and return only the interaction term for the sweet subcategory
model_results <- tidy(model_fit, conf.int = TRUE)  # it is the 95% CI by default
```
```{r}
# ---  Calculate Conditional Effects Correctly Using Posterior Draws ---
# This is the statistically sound way to calculate the effect for each group.
# It uses the full posterior distribution to correctly propagate uncertainty.

# First, extract the posterior draws for the relevant coefficients.
# The 'as_draws_df' function converts the model's posterior samples into a tidy data frame.
posterior_draws <- as_draws_df(model_fit)

# Now, calculate the conditional effect for each draw.
conditional_effects_draws <- posterior_draws %>%
  transmute(
    # The effect for the Ablative group is just its own coefficient.
    `Ablative (High Intensity)` = `b_fg_sweets:empiricalTRUE`,
    
    # The effect for the Reduced group is the baseline effect + its interaction term.
    `Reduced Intensity` = `b_fg_sweets:empiricalTRUE` + `b_fg_sweets:empiricalTRUE:intensityreduced`,
    
    # The effect for the Non-Ablative group is the baseline effect + its interaction term.
    `Non-Ablative` = `b_fg_sweets:empiricalTRUE` + `b_fg_sweets:empiricalTRUE:intensitynonablative`
  )

# ---  Summarize the Posterior to Get Point Estimates and Intervals ---
# Now we summarize the thousands of draws for each conditional effect into a
# point estimate (the mean of the draws) and a credible interval (the quantiles).

plot_data <- conditional_effects_draws %>%
  # Convert the data to a long format for easy summarization and plotting
  pivot_longer(
    cols = everything(),
    names_to = "term_label",
    values_to = "estimate"
  ) %>%
  # Group by each term to summarize
  group_by(term_label) %>%
  # Use mean_qi to get the mean (point estimate) and the 95% credible interval
  mean_qi(estimate) %>%
  # Rename columns to match the plotting code below
  rename(conf.low = .lower, conf.high = .upper) %>%
  # Make the labels a factor to control their order on the plot
  mutate(term_label = fct_relevel(term_label, "Ablative (High Intensity)", "Reduced Intensity", "Non-Ablative")) %>% 
  mutate(is_significant = (conf.low * conf.high) > 0)


# --- 4. Create the More Intuitive Coefficient Plot ---
ggplot(plot_data, aes(x = estimate, y = term_label)) +
  # Add a vertical line at zero. If a credible interval crosses this line,
  # the effect is not statistically significant.
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey70") +
  
  # Add the error bars (the "whiskers") representing the 95% credible interval
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high,  color = is_significant), height = 0.2, linewidth = 0.8) +
  
  # Add the points representing the model's posterior mean for each term
  geom_point(size = 4, aes(  color = is_significant)) +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "gray50"), guide = "none") +
  
  # Add labels and a title
  labs(
    title = "Effect of Sweets + Antibiotics on Microbiome Diversity",
    subtitle = "Shown for each conditioning intensity group",
    x = "Estimated Change in Log(Alpha Diversity)",
    y = "" # No y-axis label needed
  ) +
  
  # Use a clean theme
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major.y = element_blank(), # Remove horizontal grid lines
    plot.title.position = "plot"
  )

```

